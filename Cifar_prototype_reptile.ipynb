{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMA+vYHzbDwbakayOAhRX42",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psmouli14/final_project/blob/main/Cifar_prototype_reptile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DOlu814zHVl8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "lqjRUIPrI9dN",
        "outputId": "a6c6741a-1161-4df0-9989-0169255906b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2d81a3c2-9fe4-4428-9733-4aab0a29207e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2d81a3c2-9fe4-4428-9733-4aab0a29207e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cifar-100-python.tar.gz to cifar-100-python.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -zxvf cifar-100-python.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5xXwzyFJAv8",
        "outputId": "bf2e844a-40cd-455a-9e64-edf2fe277e09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar-100-python/\n",
            "cifar-100-python/file.txt~\n",
            "cifar-100-python/train\n",
            "cifar-100-python/test\n",
            "cifar-100-python/meta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        cifar_dict = pickle.load(fo, encoding='bytes')\n",
        "    return cifar_dict"
      ],
      "metadata": {
        "id": "JDFUbAHEZ-An"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta = unpickle('cifar-100-python/meta')\n",
        "train = unpickle('cifar-100-python/train')\n",
        "test = unpickle('cifar-100-python/test')"
      ],
      "metadata": {
        "id": "5-Y9nNg_auc4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_keys = list(meta.keys())\n",
        "meta_keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz-Qix47bL0A",
        "outputId": "e02ab565-f29a-49a0-a635-6bbac78c304e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'fine_label_names', b'coarse_label_names']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Classes = pd.DataFrame(meta[b'fine_label_names'],columns = ['Classes'])"
      ],
      "metadata": {
        "id": "tqkGn9fvbeoG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdm6adGobhyu",
        "outputId": "81326874-6cae-48e9-9958-f63ae966e737"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_keys = list(train.keys())\n",
        "training_keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJv2yegldRZK",
        "outputId": "dde274ee-ae38-4ba4-de40-7aa2c2fd4fe3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_keys = list(test.keys())\n",
        "test_keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Unfmv4Udsqf",
        "outputId": "33a2ebd5-ed0f-4928-bcc7-7d03ed23ffcc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'filenames', b'batch_label', b'fine_labels', b'coarse_labels', b'data']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train[b'data']\n",
        "test_images = test[b'data']\n",
        "train_images.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqr9ImIJebNg",
        "outputId": "46e6e8f8-da58-42de-860a-1320e5ed789c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3072)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKpQCyfyfakr",
        "outputId": "ce4d6221-bdb6-446d-e3fb-29f1ae61bf31"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3072)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "train_images = train_images.reshape(50000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
        "train_images = tf.cast(train_images, tf.float32)\n",
        "train_images.shape\n",
        "train_images = train_images/255"
      ],
      "metadata": {
        "id": "2rqJ-jGugc8H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(train_images[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "E3Akskpphg0m",
        "outputId": "625ae0ae-bfe0-4da4-cb87-d1704e9b9f28"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc1800147d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = test_images.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
        "test_images = tf.cast(test_images, tf.float32)\n",
        "test_images.shape\n",
        "test_images = test_images/255"
      ],
      "metadata": {
        "id": "_3HxwYtkddDt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we build the labels and images as lists\n",
        "train_labels = train[b'fine_labels']\n",
        "test_labels = test[b'fine_labels']"
      ],
      "metadata": {
        "id": "4AJPyU-MtAlV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_labels), len(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uM_FiFNjVqw",
        "outputId": "c3463a9e-345a-4f7a-8c7c-5a77df32f3d0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_ways = [5, 5, 12, 12, 15]\n",
        "num_shots = [5, 1, 5, 1, 3]\n",
        "learning_rate = 0.001\n",
        "img_width = 32\n",
        "img_height = 32\n",
        "channels = 3\n",
        "learning_rate = 0.001\n",
        "num_classes = 100"
      ],
      "metadata": {
        "id": "W4Ypmp1-jb6m"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_images.shape)\n",
        "print(train_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ_Io6mQ2N2i",
        "outputId": "48f1e604-a660-4d32-a335-4061295c7ce4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 32, 3)\n",
            "(50000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split train into train and val\n",
        "train_images_split = np.zeros([40000, img_width , img_height, channels], dtype=np.float32)\n",
        "val_images_split = np.zeros([10000, img_width , img_height, channels], dtype=np.float32)\n",
        "train_labels_split = np.zeros(40000)\n",
        "val_labels_split = np.zeros(10000)\n",
        "\n",
        "train_split = 400\n",
        "val_split = 100\n",
        "for class_ in range(len(Classes)):\n",
        "  train_start_index = class_ * 500\n",
        "  train_end_index = train_start_index + train_split\n",
        "  train_index = class_ * train_split\n",
        "  val_start_index = train_end_index\n",
        "  val_end_index = val_start_index + val_split\n",
        "  val_index = class_ * val_split\n",
        "\n",
        "  train_images_split[train_index : train_index + train_split] = train_images[train_start_index: train_end_index]\n",
        "  val_images_split[val_index : val_index + val_split] = train_images[val_start_index : val_end_index]\n",
        "\n",
        "\n",
        "  train_labels_split[train_index : train_index + train_split] = train_labels[train_start_index : train_end_index]\n",
        "  val_labels_split[val_index : val_index + val_split] = train_labels[val_start_index : val_end_index]\n"
      ],
      "metadata": {
        "id": "MGAzDc-p3DAZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_images.shape)\n",
        "print(train_images_split.shape)\n",
        "print(val_images_split.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl8-Bw6yhkVh",
        "outputId": "ec0870d0-b3c7-4494-bcf8-d256d7b88cf5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 32, 3)\n",
            "(40000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_batch(dataset, labels, num_way, num_shot, num_query, no_of_classes):\n",
        "  episodic_classes = np.random.permutation(no_of_classes)[:num_way]\n",
        "  support = np.zeros([num_way, num_shot, img_width , img_height, channels], dtype=np.float32)\n",
        "  query = np.zeros([num_way, num_query, img_width , img_height, channels], dtype=np.float32)\n",
        "\n",
        "  for index, class_ in enumerate(episodic_classes):\n",
        "    indices = find_indices(labels, class_)\n",
        "    #check that the size is greater than num_shot + num_query\n",
        "    selected = np.random.permutation(indices)[:num_shot + num_query]\n",
        "    for support_index in range(num_shot):\n",
        "       support[index][support_index] = dataset[selected[support_index]] \n",
        "    for query_index in range(num_query):\n",
        "       query[index][query_index] = dataset[selected[num_shot + query_index]]  \n",
        "    \n",
        "  return support, query\n",
        "\n",
        "def find_indices(list_to_check, item_to_find):\n",
        "  indices = []\n",
        "  for idx, value in enumerate(list_to_check):\n",
        "    if value == item_to_find:\n",
        "      indices.append(idx)\n",
        "  return indices\n",
        "\n"
      ],
      "metadata": {
        "id": "t8iENgdpyI8r"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support, query = get_next_batch(val_images_split, val_labels_split, 20, 7, 3, 100)"
      ],
      "metadata": {
        "id": "aslgCiUk-stA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZCM-q4w_XNC",
        "outputId": "bcffb72a-20cd-4f17-f9aa-1f5bea523617"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 7, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdYHI3Je_asi",
        "outputId": "e47f7773-98e7-4ef1-82df-b9b1959937aa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 3, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(dataset, index, image_number):\n",
        "  plt.figure(figsize=(2,3))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(dataset[index][image_number])\n"
      ],
      "metadata": {
        "id": "dsjaPAdV_eMB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(support, 4, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "3pP-fPoOHXrJ",
        "outputId": "acaabd6e-0202-45d0-8886-cc42ffb8ba4d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 144x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(query, 4, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "Tf_USxDCl7Gv",
        "outputId": "db222758-8b8c-44db-8631-15c03389cd65"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 144x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras  \n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model"
      ],
      "metadata": {
        "id": "yQsRfRaEYaSh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Dropout, GlobalMaxPooling2D\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "class Prototypical(Model):\n",
        "    \n",
        "    def __init__(self, n_support, n_query, w, h, c):\n",
        "        super(Prototypical, self).__init__()\n",
        "        self.w, self.h, self.c = w, h, c\n",
        "\n",
        "        # Encoder as ResNet like CNN with 4 blocks\n",
        "        self.encoder = keras.Sequential([\n",
        "            keras.layers.Conv2D(filters=64, kernel_size=3, padding='same'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.ReLU(),\n",
        "            keras.layers.MaxPool2D((2, 2)),\n",
        "\n",
        "            keras.layers.Conv2D(filters=64, kernel_size=3, padding='same'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.ReLU(),\n",
        "            keras.layers.MaxPool2D((2, 2)),\n",
        "\n",
        "            keras.layers.Conv2D(filters=64, kernel_size=3, padding='same'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.ReLU(),\n",
        "            keras.layers.MaxPool2D((2, 2)),\n",
        "\n",
        "            keras.layers.Conv2D(filters=64, kernel_size=3, padding='same'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.ReLU(),\n",
        "            keras.layers.MaxPool2D((2, 2)), Flatten()]\n",
        "        )\n",
        "\n",
        "    def call(self, support, query):\n",
        "        n_class = support.shape[0]\n",
        "        n_support = support.shape[1]\n",
        "        n_query = query.shape[1]\n",
        "        y = np.tile(np.arange(n_class)[:, np.newaxis], (1, n_query))\n",
        "        y_onehot = tf.cast(tf.one_hot(y, n_class), tf.float32)\n",
        "\n",
        "        # correct indices of support samples (just natural order)\n",
        "        target_inds = tf.reshape(tf.range(n_class), [n_class, 1])\n",
        "        target_inds = tf.tile(target_inds, [1, n_query])\n",
        "\n",
        "        # merge support and query to forward through encoder\n",
        "        cat = tf.concat([\n",
        "            tf.reshape(support, [n_class * n_support,\n",
        "                                 self.w, self.h, self.c]),\n",
        "            tf.reshape(query, [n_class * n_query,\n",
        "                               self.w, self.h, self.c])], axis=0)\n",
        "        z = self.encoder(cat)\n",
        "\n",
        "        # Divide embedding into support and query\n",
        "        z_prototypes = tf.reshape(z[:n_class * n_support],\n",
        "                                  [n_class, n_support, z.shape[-1]])\n",
        "        # Prototypes are means of n_support examples\n",
        "        z_prototypes = tf.math.reduce_mean(z_prototypes, axis=1)\n",
        "        z_query = z[n_class * n_support:]\n",
        "\n",
        "        # Calculate distances between query and prototypes\n",
        "        dists = euclidean_distance(z_query, z_prototypes)\n",
        "\n",
        "        # log softmax of calculated distances\n",
        "        log_p_y = tf.nn.log_softmax(-dists, axis=-1)\n",
        "        log_p_y = tf.reshape(log_p_y, [n_class, n_query, -1])\n",
        "        \n",
        "        loss = -tf.reduce_mean(tf.reshape(tf.reduce_sum(tf.multiply(y_onehot, log_p_y), axis=-1), [-1]))\n",
        "        eq = tf.cast(tf.equal(\n",
        "            tf.cast(tf.argmax(log_p_y, axis=-1), tf.int32), \n",
        "            tf.cast(y, tf.int32)), tf.float32)\n",
        "        acc = tf.reduce_mean(eq)\n",
        "        return loss, acc\n",
        "\n",
        "    def save(self, model_path):\n",
        "        self.encoder.save(model_path)\n",
        "\n",
        "    def load(self, model_path):\n",
        "        self.encoder(tf.zeros([1, self.w, self.h, self.c]))\n",
        "        self.encoder.load_weights(model_path)"
      ],
      "metadata": {
        "id": "RYIxk1m1HcYH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(a, b):\n",
        "\n",
        "    N, D = tf.shape(a)[0], tf.shape(a)[1]\n",
        "    M = tf.shape(b)[0]\n",
        "    a = tf.tile(tf.expand_dims(a, axis=1), (1, M, 1))\n",
        "    b = tf.tile(tf.expand_dims(b, axis=0), (N, 1, 1))\n",
        "    return tf.reduce_mean(tf.square(a - b), axis=2)"
      ],
      "metadata": {
        "id": "9qLG5YjxYdH8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number of classes\n",
        "num_way = num_ways[0] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[0]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[0] \n",
        "\n",
        "train_loss = tf.metrics.Mean(name='train_loss')\n",
        "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "num_epochs = 80\n",
        "num_episodes = 100\n",
        "save_path = \"./results/models/cifar100_train0.h5\"\n",
        "\n",
        "least_loss = {'least_loss': 100.00}\n",
        "\n",
        "@tf.function\n",
        "def loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "@tf.function\n",
        "def train_step(support, query):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  train_loss(loss)\n",
        "  train_acc(acc)\n",
        "\n",
        "@tf.function\n",
        "def val_step(loss_func, support, query):\n",
        "  loss, acc = loss_func(support, query)\n",
        "  val_loss(loss)\n",
        "  val_acc(acc)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "    train_support, train_query = get_next_batch(train_images_split, train_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "    train_step(train_support, train_query)\n",
        "\n",
        "  cur_loss = train_loss.result().numpy()\n",
        "  if cur_loss < least_loss['least_loss']:\n",
        "      print(\"Saving new best model with loss: \", cur_loss)\n",
        "      least_loss['least_loss'] = cur_loss\n",
        "      model.save(save_path)\n",
        "      \n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
        "  print(template.format(epoch + 1, train_loss.result(), train_acc.result() * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm-NC26kYqEy",
        "outputId": "ddbdd83b-7859-4e00-d21f-f026074677a4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5534722\n",
            "Epoch 1, Loss: 1.5534721612930298, Accuracy: 33.320003509521484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.3736037\n",
            "Epoch 2, Loss: 1.3736037015914917, Accuracy: 43.52000427246094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.3290579\n",
            "Epoch 3, Loss: 1.3290579319000244, Accuracy: 45.52000045776367\n",
            "Epoch 4, Loss: 1.3447411060333252, Accuracy: 44.000003814697266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.296051\n",
            "Epoch 5, Loss: 1.296051025390625, Accuracy: 47.72000503540039\n",
            "Epoch 6, Loss: 1.3193376064300537, Accuracy: 45.76000213623047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.295448\n",
            "Epoch 7, Loss: 1.2954479455947876, Accuracy: 47.4000129699707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.2816093\n",
            "Epoch 8, Loss: 1.281609296798706, Accuracy: 47.07999801635742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.2366254\n",
            "Epoch 9, Loss: 1.2366254329681396, Accuracy: 48.239990234375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.2277669\n",
            "Epoch 10, Loss: 1.2277668714523315, Accuracy: 50.639991760253906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.2266313\n",
            "Epoch 11, Loss: 1.2266312837600708, Accuracy: 49.79998779296875\n",
            "Epoch 12, Loss: 1.2507644891738892, Accuracy: 50.96000289916992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.1930882\n",
            "Epoch 13, Loss: 1.193088173866272, Accuracy: 51.279998779296875\n",
            "Epoch 14, Loss: 1.2376160621643066, Accuracy: 49.399993896484375\n",
            "Epoch 15, Loss: 1.2153370380401611, Accuracy: 51.519989013671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.1844034\n",
            "Epoch 16, Loss: 1.184403419494629, Accuracy: 52.43999481201172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.1769506\n",
            "Epoch 17, Loss: 1.1769505739212036, Accuracy: 53.07999801635742\n",
            "Epoch 18, Loss: 1.177234172821045, Accuracy: 53.43999099731445\n",
            "Epoch 19, Loss: 1.200439453125, Accuracy: 52.03999710083008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.1586424\n",
            "Epoch 20, Loss: 1.1586424112319946, Accuracy: 53.480018615722656\n",
            "Epoch 21, Loss: 1.1748119592666626, Accuracy: 53.03998565673828\n",
            "Epoch 22, Loss: 1.1652559041976929, Accuracy: 54.000003814697266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.1518946\n",
            "Epoch 23, Loss: 1.1518945693969727, Accuracy: 53.84001159667969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.1215864\n",
            "Epoch 24, Loss: 1.1215864419937134, Accuracy: 54.720001220703125\n",
            "Epoch 25, Loss: 1.1349461078643799, Accuracy: 54.71998596191406\n",
            "Epoch 26, Loss: 1.1492282152175903, Accuracy: 55.64000701904297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.0518594\n",
            "Epoch 27, Loss: 1.0518593788146973, Accuracy: 58.079994201660156\n",
            "Epoch 28, Loss: 1.1573928594589233, Accuracy: 52.95999526977539\n",
            "Epoch 29, Loss: 1.05605947971344, Accuracy: 58.440006256103516\n",
            "Epoch 30, Loss: 1.0930061340332031, Accuracy: 56.31999206542969\n",
            "Epoch 31, Loss: 1.0836060047149658, Accuracy: 55.519996643066406\n",
            "Epoch 32, Loss: 1.1142264604568481, Accuracy: 53.920005798339844\n",
            "Epoch 33, Loss: 1.0534673929214478, Accuracy: 57.60000228881836\n",
            "Epoch 34, Loss: 1.065067172050476, Accuracy: 57.5999870300293\n",
            "Epoch 35, Loss: 1.078088402748108, Accuracy: 57.04001235961914\n",
            "Epoch 36, Loss: 1.0923267602920532, Accuracy: 56.480003356933594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.0471588\n",
            "Epoch 37, Loss: 1.0471588373184204, Accuracy: 58.16000747680664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.0104426\n",
            "Epoch 38, Loss: 1.0104426145553589, Accuracy: 60.160003662109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  0.9983528\n",
            "Epoch 39, Loss: 0.9983528256416321, Accuracy: 60.880001068115234\n",
            "Epoch 40, Loss: 1.046949863433838, Accuracy: 59.16000747680664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  0.9814155\n",
            "Epoch 41, Loss: 0.9814155101776123, Accuracy: 61.43998336791992\n",
            "Epoch 42, Loss: 0.9826287031173706, Accuracy: 61.27998352050781\n",
            "Epoch 43, Loss: 1.0237215757369995, Accuracy: 59.31999206542969\n",
            "Epoch 44, Loss: 1.0517634153366089, Accuracy: 58.52000045776367\n",
            "Epoch 45, Loss: 0.9924248456954956, Accuracy: 60.60000228881836\n",
            "Epoch 46, Loss: 1.0110911130905151, Accuracy: 59.92000198364258\n",
            "Epoch 47, Loss: 0.9968621730804443, Accuracy: 60.24000549316406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  0.9484034\n",
            "Epoch 48, Loss: 0.9484034180641174, Accuracy: 62.12000274658203\n",
            "Epoch 49, Loss: 0.9891582727432251, Accuracy: 62.27998733520508\n",
            "Epoch 50, Loss: 1.026911735534668, Accuracy: 59.239994049072266\n",
            "Epoch 51, Loss: 1.0124149322509766, Accuracy: 58.55998229980469\n",
            "Epoch 52, Loss: 0.9873693585395813, Accuracy: 60.999996185302734\n",
            "Epoch 53, Loss: 0.9524909853935242, Accuracy: 62.519996643066406\n",
            "Epoch 54, Loss: 0.9566190242767334, Accuracy: 61.760009765625\n",
            "Epoch 55, Loss: 0.9961177706718445, Accuracy: 60.3599967956543\n",
            "Epoch 56, Loss: 0.9704766869544983, Accuracy: 62.23999786376953\n",
            "Epoch 57, Loss: 0.95377516746521, Accuracy: 62.87997817993164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  0.9304436\n",
            "Epoch 58, Loss: 0.9304435849189758, Accuracy: 62.87997817993164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  0.92135435\n",
            "Epoch 59, Loss: 0.921354353427887, Accuracy: 65.12001037597656\n",
            "Epoch 60, Loss: 0.9868370294570923, Accuracy: 60.27999496459961\n",
            "Epoch 61, Loss: 0.9685676097869873, Accuracy: 61.91999435424805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  0.91445374\n",
            "Epoch 62, Loss: 0.9144537448883057, Accuracy: 64.239990234375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  0.8870556\n",
            "Epoch 63, Loss: 0.8870555758476257, Accuracy: 65.04000091552734\n",
            "Epoch 64, Loss: 0.9200125336647034, Accuracy: 64.03999328613281\n",
            "Epoch 65, Loss: 0.9240662455558777, Accuracy: 64.19999694824219\n",
            "Epoch 66, Loss: 0.9233133792877197, Accuracy: 64.07999420166016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  0.8765032\n",
            "Epoch 67, Loss: 0.8765032291412354, Accuracy: 66.03999328613281\n",
            "Epoch 68, Loss: 0.9317643046379089, Accuracy: 62.400001525878906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  0.86398214\n",
            "Epoch 69, Loss: 0.8639821410179138, Accuracy: 66.51998138427734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  0.82423866\n",
            "Epoch 70, Loss: 0.824238657951355, Accuracy: 65.87998962402344\n",
            "Epoch 71, Loss: 0.9427096843719482, Accuracy: 62.35999298095703\n",
            "Epoch 72, Loss: 0.8492876291275024, Accuracy: 68.07999420166016\n",
            "Epoch 73, Loss: 0.9019239544868469, Accuracy: 63.31999206542969\n",
            "Epoch 74, Loss: 0.9079892039299011, Accuracy: 64.3599853515625\n",
            "Epoch 75, Loss: 0.8947383761405945, Accuracy: 64.79999542236328\n",
            "Epoch 76, Loss: 0.8815118670463562, Accuracy: 65.87999725341797\n",
            "Epoch 77, Loss: 0.8734992742538452, Accuracy: 66.36000061035156\n",
            "Epoch 78, Loss: 0.8324078321456909, Accuracy: 65.87999725341797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  0.78943884\n",
            "Epoch 79, Loss: 0.7894388437271118, Accuracy: 70.23998260498047\n",
            "Epoch 80, Loss: 0.8621929883956909, Accuracy: 66.35997772216797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#number of classes\n",
        "num_way = num_ways[1] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[1]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[1] \n",
        "\n",
        "train_loss = tf.metrics.Mean(name='train_loss')\n",
        "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "num_epochs = 80\n",
        "num_episodes = 100\n",
        "save_path = \"./results/models/cifar100_train1.h5\"\n",
        "\n",
        "least_loss = {'least_loss': 100.00}\n",
        "\n",
        "@tf.function\n",
        "def loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "@tf.function\n",
        "def train_step(support, query):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  train_loss(loss)\n",
        "  train_acc(acc)\n",
        "\n",
        "@tf.function\n",
        "def val_step(loss_func, support, query):\n",
        "  loss, acc = loss_func(support, query)\n",
        "  val_loss(loss)\n",
        "  val_acc(acc)\n",
        "\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "    train_support, train_query = get_next_batch(train_images_split, train_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "    train_step(train_support, train_query)\n",
        "\n",
        "  cur_loss = train_loss.result().numpy()\n",
        "  if cur_loss < least_loss['least_loss']:\n",
        "      print(\"Saving new best model with loss: \", cur_loss)\n",
        "      least_loss['least_loss'] = cur_loss\n",
        "      model.save(save_path)\n",
        "      \n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
        "  print(template.format(epoch + 1, train_loss.result(), train_acc.result() * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUPsjcRcIkBR",
        "outputId": "e6f5604d-8132-4557-8103-4d31252e275a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.598916\n",
            "Epoch 1, Loss: 1.5989160537719727, Accuracy: 28.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5852009\n",
            "Epoch 2, Loss: 1.5852009057998657, Accuracy: 31.599998474121094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5817511\n",
            "Epoch 3, Loss: 1.5817511081695557, Accuracy: 29.800003051757812\n",
            "Epoch 4, Loss: 1.6080043315887451, Accuracy: 27.000003814697266\n",
            "Epoch 5, Loss: 1.5823051929473877, Accuracy: 33.000003814697266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.578149\n",
            "Epoch 6, Loss: 1.5781489610671997, Accuracy: 28.800004959106445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5643615\n",
            "Epoch 7, Loss: 1.5643614530563354, Accuracy: 31.60000228881836\n",
            "Epoch 8, Loss: 1.567354440689087, Accuracy: 30.599998474121094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5524806\n",
            "Epoch 9, Loss: 1.5524805784225464, Accuracy: 31.20000457763672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5378116\n",
            "Epoch 10, Loss: 1.5378116369247437, Accuracy: 32.40000915527344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5129989\n",
            "Epoch 11, Loss: 1.5129989385604858, Accuracy: 37.200008392333984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.4889468\n",
            "Epoch 12, Loss: 1.488946795463562, Accuracy: 35.60001754760742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.4708084\n",
            "Epoch 13, Loss: 1.4708083868026733, Accuracy: 34.800010681152344\n",
            "Epoch 14, Loss: 1.5144222974777222, Accuracy: 34.40000915527344\n",
            "Epoch 15, Loss: 1.5228052139282227, Accuracy: 35.400001525878906\n",
            "Epoch 16, Loss: 1.5382018089294434, Accuracy: 33.599998474121094\n",
            "Epoch 17, Loss: 1.5330047607421875, Accuracy: 34.80001449584961\n",
            "Epoch 18, Loss: 1.5190494060516357, Accuracy: 34.600006103515625\n",
            "Epoch 19, Loss: 1.5005602836608887, Accuracy: 36.399993896484375\n",
            "Epoch 20, Loss: 1.5344680547714233, Accuracy: 31.000011444091797\n",
            "Epoch 21, Loss: 1.5078816413879395, Accuracy: 33.200008392333984\n",
            "Epoch 22, Loss: 1.506223440170288, Accuracy: 35.4000129699707\n",
            "Epoch 23, Loss: 1.5174740552902222, Accuracy: 32.400001525878906\n",
            "Epoch 24, Loss: 1.5020012855529785, Accuracy: 34.4000129699707\n",
            "Epoch 25, Loss: 1.5024951696395874, Accuracy: 34.600013732910156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.4423027\n",
            "Epoch 26, Loss: 1.4423027038574219, Accuracy: 38.600006103515625\n",
            "Epoch 27, Loss: 1.4931401014328003, Accuracy: 35.4000129699707\n",
            "Epoch 28, Loss: 1.4908032417297363, Accuracy: 38.000003814697266\n",
            "Epoch 29, Loss: 1.4961658716201782, Accuracy: 33.60000228881836\n",
            "Epoch 30, Loss: 1.5339508056640625, Accuracy: 31.400007247924805\n",
            "Epoch 31, Loss: 1.4967679977416992, Accuracy: 31.80000114440918\n",
            "Epoch 32, Loss: 1.4739861488342285, Accuracy: 36.60000228881836\n",
            "Epoch 33, Loss: 1.5188522338867188, Accuracy: 32.600006103515625\n",
            "Epoch 34, Loss: 1.4496883153915405, Accuracy: 36.599998474121094\n",
            "Epoch 35, Loss: 1.4943565130233765, Accuracy: 34.000003814697266\n",
            "Epoch 36, Loss: 1.4980080127716064, Accuracy: 38.400001525878906\n",
            "Epoch 37, Loss: 1.485076904296875, Accuracy: 34.80000686645508\n",
            "Epoch 38, Loss: 1.4494316577911377, Accuracy: 37.0\n",
            "Epoch 39, Loss: 1.4912165403366089, Accuracy: 38.60001754760742\n",
            "Epoch 40, Loss: 1.4760830402374268, Accuracy: 34.600006103515625\n",
            "Epoch 41, Loss: 1.4653781652450562, Accuracy: 33.20000457763672\n",
            "Epoch 42, Loss: 1.4807384014129639, Accuracy: 36.800010681152344\n",
            "Epoch 43, Loss: 1.447616696357727, Accuracy: 37.60000228881836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.4130962\n",
            "Epoch 44, Loss: 1.4130961894989014, Accuracy: 38.4000129699707\n",
            "Epoch 45, Loss: 1.4841710329055786, Accuracy: 34.80000305175781\n",
            "Epoch 46, Loss: 1.485864520072937, Accuracy: 33.20000076293945\n",
            "Epoch 47, Loss: 1.4857975244522095, Accuracy: 34.20000457763672\n",
            "Epoch 48, Loss: 1.45671808719635, Accuracy: 36.40001678466797\n",
            "Epoch 49, Loss: 1.4691966772079468, Accuracy: 37.20000457763672\n",
            "Epoch 50, Loss: 1.4732794761657715, Accuracy: 39.60001754760742\n",
            "Epoch 51, Loss: 1.4814844131469727, Accuracy: 35.40000534057617\n",
            "Epoch 52, Loss: 1.5034397840499878, Accuracy: 32.600006103515625\n",
            "Epoch 53, Loss: 1.4641908407211304, Accuracy: 37.4000129699707\n",
            "Epoch 54, Loss: 1.4842182397842407, Accuracy: 38.400001525878906\n",
            "Epoch 55, Loss: 1.4482346773147583, Accuracy: 39.4000129699707\n",
            "Epoch 56, Loss: 1.4758487939834595, Accuracy: 32.200008392333984\n",
            "Epoch 57, Loss: 1.4445216655731201, Accuracy: 38.60000991821289\n",
            "Epoch 58, Loss: 1.4472090005874634, Accuracy: 36.0\n",
            "Epoch 59, Loss: 1.450697898864746, Accuracy: 39.600013732910156\n",
            "Epoch 60, Loss: 1.4605761766433716, Accuracy: 36.00000762939453\n",
            "Epoch 61, Loss: 1.4638662338256836, Accuracy: 36.400020599365234\n",
            "Epoch 62, Loss: 1.4307612180709839, Accuracy: 39.800010681152344\n",
            "Epoch 63, Loss: 1.4441213607788086, Accuracy: 37.600006103515625\n",
            "Epoch 64, Loss: 1.433594822883606, Accuracy: 37.60000228881836\n",
            "Epoch 65, Loss: 1.4272254705429077, Accuracy: 40.600006103515625\n",
            "Epoch 66, Loss: 1.420045018196106, Accuracy: 39.80001449584961\n",
            "Epoch 67, Loss: 1.4716384410858154, Accuracy: 36.40000534057617\n",
            "Epoch 68, Loss: 1.4399360418319702, Accuracy: 38.39999771118164\n",
            "Epoch 69, Loss: 1.442022442817688, Accuracy: 37.20000076293945\n",
            "Epoch 70, Loss: 1.44417405128479, Accuracy: 36.200016021728516\n",
            "Epoch 71, Loss: 1.4577122926712036, Accuracy: 36.000003814697266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.4085362\n",
            "Epoch 72, Loss: 1.4085361957550049, Accuracy: 39.600013732910156\n",
            "Epoch 73, Loss: 1.4249298572540283, Accuracy: 39.60000991821289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.3959558\n",
            "Epoch 74, Loss: 1.3959558010101318, Accuracy: 40.60000991821289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.3678391\n",
            "Epoch 75, Loss: 1.3678390979766846, Accuracy: 42.00000762939453\n",
            "Epoch 76, Loss: 1.4662060737609863, Accuracy: 38.00000762939453\n",
            "Epoch 77, Loss: 1.4575107097625732, Accuracy: 35.20000457763672\n",
            "Epoch 78, Loss: 1.4110838174819946, Accuracy: 41.20000457763672\n",
            "Epoch 79, Loss: 1.4066166877746582, Accuracy: 39.800018310546875\n",
            "Epoch 80, Loss: 1.4306819438934326, Accuracy: 41.80000686645508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#number of classes\n",
        "num_way = num_ways[2] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[2]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[2] \n",
        "\n",
        "train_loss = tf.metrics.Mean(name='train_loss')\n",
        "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "num_epochs = 80\n",
        "num_episodes = 100\n",
        "save_path = \"./results/models/cifar100_train2.h5\"\n",
        "\n",
        "least_loss = {'least_loss': 100.00}\n",
        "\n",
        "@tf.function\n",
        "def loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "@tf.function\n",
        "def train_step(support, query):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  train_loss(loss)\n",
        "  train_acc(acc)\n",
        "\n",
        "@tf.function\n",
        "def val_step(loss_func, support, query):\n",
        "  loss, acc = loss_func(support, query)\n",
        "  val_loss(loss)\n",
        "  val_acc(acc)\n",
        "\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "    train_support, train_query = get_next_batch(train_images_split, train_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "    train_step(train_support, train_query)\n",
        "\n",
        "  cur_loss = train_loss.result().numpy()\n",
        "  if cur_loss < least_loss['least_loss']:\n",
        "      print(\"Saving new best model with loss: \", cur_loss)\n",
        "      least_loss['least_loss'] = cur_loss\n",
        "      model.save(save_path)\n",
        "      \n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
        "  print(template.format(epoch + 1, train_loss.result(), train_acc.result() * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBx2LroOIkax",
        "outputId": "6678a3ef-f29b-4afc-b9c4-623f278abdca"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.3277044\n",
            "Epoch 1, Loss: 2.327704429626465, Accuracy: 20.883338928222656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.152342\n",
            "Epoch 2, Loss: 2.1523420810699463, Accuracy: 26.40000343322754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.0893743\n",
            "Epoch 3, Loss: 2.089374303817749, Accuracy: 28.583335876464844\n",
            "Epoch 4, Loss: 2.102234363555908, Accuracy: 28.049999237060547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.0182314\n",
            "Epoch 5, Loss: 2.0182313919067383, Accuracy: 30.583337783813477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.9964443\n",
            "Epoch 6, Loss: 1.9964443445205688, Accuracy: 32.88333511352539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.9666821\n",
            "Epoch 7, Loss: 1.9666820764541626, Accuracy: 33.83332824707031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.9399563\n",
            "Epoch 8, Loss: 1.9399563074111938, Accuracy: 34.15000534057617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.8824562\n",
            "Epoch 9, Loss: 1.8824561834335327, Accuracy: 36.266658782958984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.8788959\n",
            "Epoch 10, Loss: 1.878895878791809, Accuracy: 37.166664123535156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.8458785\n",
            "Epoch 11, Loss: 1.8458784818649292, Accuracy: 38.18333435058594\n",
            "Epoch 12, Loss: 1.8638414144515991, Accuracy: 37.10000228881836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.8230033\n",
            "Epoch 13, Loss: 1.8230032920837402, Accuracy: 38.55000305175781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.7893835\n",
            "Epoch 14, Loss: 1.7893835306167603, Accuracy: 39.41666793823242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.7625352\n",
            "Epoch 15, Loss: 1.7625352144241333, Accuracy: 40.23332977294922\n",
            "Epoch 16, Loss: 1.772049903869629, Accuracy: 40.79999542236328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.7203424\n",
            "Epoch 17, Loss: 1.7203423976898193, Accuracy: 42.5333251953125\n",
            "Epoch 18, Loss: 1.7525224685668945, Accuracy: 40.91667556762695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.6946677\n",
            "Epoch 19, Loss: 1.6946676969528198, Accuracy: 43.08333969116211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.6802619\n",
            "Epoch 20, Loss: 1.6802618503570557, Accuracy: 43.56667709350586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.6796029\n",
            "Epoch 21, Loss: 1.679602861404419, Accuracy: 42.85000228881836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.6546992\n",
            "Epoch 22, Loss: 1.6546992063522339, Accuracy: 44.95000457763672\n",
            "Epoch 23, Loss: 1.6568065881729126, Accuracy: 43.9333381652832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.6157924\n",
            "Epoch 24, Loss: 1.6157923936843872, Accuracy: 45.983333587646484\n",
            "Epoch 25, Loss: 1.6308842897415161, Accuracy: 44.116661071777344\n",
            "Epoch 26, Loss: 1.6170508861541748, Accuracy: 44.61667251586914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.6135219\n",
            "Epoch 27, Loss: 1.613521933555603, Accuracy: 45.63332748413086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5713981\n",
            "Epoch 28, Loss: 1.571398138999939, Accuracy: 47.31666946411133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5572798\n",
            "Epoch 29, Loss: 1.5572798252105713, Accuracy: 46.84999084472656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5525081\n",
            "Epoch 30, Loss: 1.5525081157684326, Accuracy: 47.68333053588867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5304375\n",
            "Epoch 31, Loss: 1.5304374694824219, Accuracy: 48.216670989990234\n",
            "Epoch 32, Loss: 1.5483105182647705, Accuracy: 48.01667022705078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5263569\n",
            "Epoch 33, Loss: 1.5263569355010986, Accuracy: 48.733333587646484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5081154\n",
            "Epoch 34, Loss: 1.5081154108047485, Accuracy: 49.233333587646484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.4919144\n",
            "Epoch 35, Loss: 1.4919143915176392, Accuracy: 49.916664123535156\n",
            "Epoch 36, Loss: 1.5240734815597534, Accuracy: 48.333335876464844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.4603766\n",
            "Epoch 37, Loss: 1.4603766202926636, Accuracy: 49.94999313354492\n",
            "Epoch 38, Loss: 1.4795070886611938, Accuracy: 50.016658782958984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.4471436\n",
            "Epoch 39, Loss: 1.4471435546875, Accuracy: 50.85000228881836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.4027656\n",
            "Epoch 40, Loss: 1.4027656316757202, Accuracy: 52.16666030883789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.3908925\n",
            "Epoch 41, Loss: 1.390892505645752, Accuracy: 53.399993896484375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.3759564\n",
            "Epoch 42, Loss: 1.375956416130066, Accuracy: 52.90000534057617\n",
            "Epoch 43, Loss: 1.4393521547317505, Accuracy: 51.650001525878906\n",
            "Epoch 44, Loss: 1.4002403020858765, Accuracy: 52.28331756591797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.3481842\n",
            "Epoch 45, Loss: 1.3481842279434204, Accuracy: 53.95000457763672\n",
            "Epoch 46, Loss: 1.3798695802688599, Accuracy: 53.40001678466797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.3233036\n",
            "Epoch 47, Loss: 1.3233035802841187, Accuracy: 55.166656494140625\n",
            "Epoch 48, Loss: 1.3252159357070923, Accuracy: 54.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.305137\n",
            "Epoch 49, Loss: 1.305137038230896, Accuracy: 56.20000457763672\n",
            "Epoch 50, Loss: 1.3064602613449097, Accuracy: 55.0000114440918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.2982035\n",
            "Epoch 51, Loss: 1.298203468322754, Accuracy: 55.68333435058594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.2743834\n",
            "Epoch 52, Loss: 1.2743834257125854, Accuracy: 57.16666030883789\n",
            "Epoch 53, Loss: 1.3456718921661377, Accuracy: 53.933326721191406\n",
            "Epoch 54, Loss: 1.3096193075180054, Accuracy: 55.78333282470703\n",
            "Epoch 55, Loss: 1.2754743099212646, Accuracy: 56.49998092651367\n",
            "Epoch 56, Loss: 1.2817851305007935, Accuracy: 55.733333587646484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.2550056\n",
            "Epoch 57, Loss: 1.2550055980682373, Accuracy: 56.966651916503906\n",
            "Epoch 58, Loss: 1.2605559825897217, Accuracy: 56.483314514160156\n",
            "Epoch 59, Loss: 1.2754523754119873, Accuracy: 57.266658782958984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.219772\n",
            "Epoch 60, Loss: 1.2197719812393188, Accuracy: 58.26666259765625\n",
            "Epoch 61, Loss: 1.2701457738876343, Accuracy: 55.99999237060547\n",
            "Epoch 62, Loss: 1.2615886926651, Accuracy: 56.633323669433594\n",
            "Epoch 63, Loss: 1.2476028203964233, Accuracy: 56.94999694824219\n",
            "Epoch 64, Loss: 1.2580047845840454, Accuracy: 56.533329010009766\n",
            "Epoch 65, Loss: 1.246607780456543, Accuracy: 57.36664962768555\n",
            "Epoch 66, Loss: 1.2305424213409424, Accuracy: 57.44998550415039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.1972601\n",
            "Epoch 67, Loss: 1.1972601413726807, Accuracy: 58.60000991821289\n",
            "Epoch 68, Loss: 1.2059634923934937, Accuracy: 59.21666717529297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.1908773\n",
            "Epoch 69, Loss: 1.1908773183822632, Accuracy: 58.79999542236328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.1791428\n",
            "Epoch 70, Loss: 1.1791428327560425, Accuracy: 60.11668014526367\n",
            "Epoch 71, Loss: 1.1947600841522217, Accuracy: 58.61664962768555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.1332852\n",
            "Epoch 72, Loss: 1.1332851648330688, Accuracy: 61.050010681152344\n",
            "Epoch 73, Loss: 1.1652140617370605, Accuracy: 60.216651916503906\n",
            "Epoch 74, Loss: 1.1521779298782349, Accuracy: 60.93332290649414\n",
            "Epoch 75, Loss: 1.167134404182434, Accuracy: 59.88331985473633\n",
            "Epoch 76, Loss: 1.1885230541229248, Accuracy: 59.916656494140625\n",
            "Epoch 77, Loss: 1.153279423713684, Accuracy: 60.41667938232422\n",
            "Epoch 78, Loss: 1.1342445611953735, Accuracy: 61.23333740234375\n",
            "Epoch 79, Loss: 1.1386643648147583, Accuracy: 60.650001525878906\n",
            "Epoch 80, Loss: 1.1347731351852417, Accuracy: 60.9333381652832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#number of classes\n",
        "num_way = num_ways[3] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[3]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[3] \n",
        "\n",
        "train_loss = tf.metrics.Mean(name='train_loss')\n",
        "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "num_epochs = 80\n",
        "num_episodes = 100\n",
        "save_path = \"./results/models/cifar100_train3.h5\"\n",
        "\n",
        "least_loss = {'least_loss': 100.00}\n",
        "\n",
        "@tf.function\n",
        "def loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "@tf.function\n",
        "def train_step(support, query):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  train_loss(loss)\n",
        "  train_acc(acc)\n",
        "\n",
        "@tf.function\n",
        "def val_step(loss_func, support, query):\n",
        "  loss, acc = loss_func(support, query)\n",
        "  val_loss(loss)\n",
        "  val_acc(acc)\n",
        "\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "    train_support, train_query = get_next_batch(train_images_split, train_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "    train_step(train_support, train_query)\n",
        "\n",
        "  cur_loss = train_loss.result().numpy()\n",
        "  if cur_loss < least_loss['least_loss']:\n",
        "      print(\"Saving new best model with loss: \", cur_loss)\n",
        "      least_loss['least_loss'] = cur_loss\n",
        "      model.save(save_path)\n",
        "      \n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
        "  print(template.format(epoch + 1, train_loss.result(), train_acc.result() * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ncZmf1mIk8o",
        "outputId": "1adccc64-2b5a-49dc-f1af-f6c4cc69ad74"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.4430752\n",
            "Epoch 1, Loss: 2.443075180053711, Accuracy: 16.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.399337\n",
            "Epoch 2, Loss: 2.39933705329895, Accuracy: 17.750001907348633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.3720853\n",
            "Epoch 3, Loss: 2.3720853328704834, Accuracy: 16.916664123535156\n",
            "Epoch 4, Loss: 2.388019323348999, Accuracy: 16.750001907348633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.3578427\n",
            "Epoch 5, Loss: 2.3578426837921143, Accuracy: 19.333330154418945\n",
            "Epoch 6, Loss: 2.3625190258026123, Accuracy: 16.66666603088379\n",
            "Epoch 7, Loss: 2.38893985748291, Accuracy: 18.75\n",
            "Epoch 8, Loss: 2.372443437576294, Accuracy: 20.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.3378482\n",
            "Epoch 9, Loss: 2.33784818649292, Accuracy: 19.750001907348633\n",
            "Epoch 10, Loss: 2.3727235794067383, Accuracy: 17.33333396911621\n",
            "Epoch 11, Loss: 2.361941337585449, Accuracy: 19.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.300271\n",
            "Epoch 12, Loss: 2.3002710342407227, Accuracy: 20.166667938232422\n",
            "Epoch 13, Loss: 2.314343214035034, Accuracy: 18.833335876464844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.297554\n",
            "Epoch 14, Loss: 2.2975540161132812, Accuracy: 21.500003814697266\n",
            "Epoch 15, Loss: 2.3280370235443115, Accuracy: 20.249998092651367\n",
            "Epoch 16, Loss: 2.3339643478393555, Accuracy: 20.583328247070312\n",
            "Epoch 17, Loss: 2.332725763320923, Accuracy: 20.0\n",
            "Epoch 18, Loss: 2.3052661418914795, Accuracy: 20.33333396911621\n",
            "Epoch 19, Loss: 2.3255155086517334, Accuracy: 20.999996185302734\n",
            "Epoch 20, Loss: 2.300858497619629, Accuracy: 21.41666603088379\n",
            "Epoch 21, Loss: 2.303891658782959, Accuracy: 21.750003814697266\n",
            "Epoch 22, Loss: 2.3146378993988037, Accuracy: 18.666667938232422\n",
            "Epoch 23, Loss: 2.3294191360473633, Accuracy: 20.333335876464844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.2911184\n",
            "Epoch 24, Loss: 2.2911183834075928, Accuracy: 21.416669845581055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.2754893\n",
            "Epoch 25, Loss: 2.275489330291748, Accuracy: 22.666669845581055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.2590635\n",
            "Epoch 26, Loss: 2.259063482284546, Accuracy: 22.666669845581055\n",
            "Epoch 27, Loss: 2.2786121368408203, Accuracy: 20.33333396911621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.2521098\n",
            "Epoch 28, Loss: 2.2521097660064697, Accuracy: 22.916667938232422\n",
            "Epoch 29, Loss: 2.304133653640747, Accuracy: 22.166667938232422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.2439187\n",
            "Epoch 30, Loss: 2.2439186573028564, Accuracy: 23.999990463256836\n",
            "Epoch 31, Loss: 2.2773425579071045, Accuracy: 20.66666603088379\n",
            "Epoch 32, Loss: 2.27547550201416, Accuracy: 22.249996185302734\n",
            "Epoch 33, Loss: 2.268187999725342, Accuracy: 22.166662216186523\n",
            "Epoch 34, Loss: 2.2604734897613525, Accuracy: 22.666664123535156\n",
            "Epoch 35, Loss: 2.2528507709503174, Accuracy: 23.916669845581055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.2232258\n",
            "Epoch 36, Loss: 2.2232258319854736, Accuracy: 24.750001907348633\n",
            "Epoch 37, Loss: 2.23514986038208, Accuracy: 22.166664123535156\n",
            "Epoch 38, Loss: 2.2445459365844727, Accuracy: 21.16666603088379\n",
            "Epoch 39, Loss: 2.2347967624664307, Accuracy: 23.083335876464844\n",
            "Epoch 40, Loss: 2.2451207637786865, Accuracy: 22.583332061767578\n",
            "Epoch 41, Loss: 2.2392477989196777, Accuracy: 22.91666603088379\n",
            "Epoch 42, Loss: 2.243637800216675, Accuracy: 23.0\n",
            "Epoch 43, Loss: 2.2612874507904053, Accuracy: 21.166667938232422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.2041855\n",
            "Epoch 44, Loss: 2.2041854858398438, Accuracy: 25.833332061767578\n",
            "Epoch 45, Loss: 2.2208847999572754, Accuracy: 23.916667938232422\n",
            "Epoch 46, Loss: 2.241102695465088, Accuracy: 23.000003814697266\n",
            "Epoch 47, Loss: 2.223487377166748, Accuracy: 25.000003814697266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.2036538\n",
            "Epoch 48, Loss: 2.2036538124084473, Accuracy: 24.58333396911621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.1926818\n",
            "Epoch 49, Loss: 2.1926817893981934, Accuracy: 25.416664123535156\n",
            "Epoch 50, Loss: 2.195246934890747, Accuracy: 25.916667938232422\n",
            "Epoch 51, Loss: 2.193237543106079, Accuracy: 25.250001907348633\n",
            "Epoch 52, Loss: 2.200535774230957, Accuracy: 25.333332061767578\n",
            "Epoch 53, Loss: 2.2285356521606445, Accuracy: 22.916671752929688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.187284\n",
            "Epoch 54, Loss: 2.187283992767334, Accuracy: 24.416664123535156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.1668365\n",
            "Epoch 55, Loss: 2.1668365001678467, Accuracy: 24.416662216186523\n",
            "Epoch 56, Loss: 2.1974921226501465, Accuracy: 24.083328247070312\n",
            "Epoch 57, Loss: 2.1767382621765137, Accuracy: 26.666667938232422\n",
            "Epoch 58, Loss: 2.1995739936828613, Accuracy: 25.333332061767578\n",
            "Epoch 59, Loss: 2.169046401977539, Accuracy: 26.16666603088379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.1498933\n",
            "Epoch 60, Loss: 2.149893283843994, Accuracy: 26.750001907348633\n",
            "Epoch 61, Loss: 2.1568217277526855, Accuracy: 27.00000762939453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.143735\n",
            "Epoch 62, Loss: 2.143734931945801, Accuracy: 28.0000057220459\n",
            "Epoch 63, Loss: 2.1495184898376465, Accuracy: 27.749998092651367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.130308\n",
            "Epoch 64, Loss: 2.130307912826538, Accuracy: 29.083330154418945\n",
            "Epoch 65, Loss: 2.133465051651001, Accuracy: 27.33333396911621\n",
            "Epoch 66, Loss: 2.151970863342285, Accuracy: 27.000001907348633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.1080394\n",
            "Epoch 67, Loss: 2.108039379119873, Accuracy: 26.833337783813477\n",
            "Epoch 68, Loss: 2.123612403869629, Accuracy: 25.416669845581055\n",
            "Epoch 69, Loss: 2.1323413848876953, Accuracy: 27.83333969116211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.0854545\n",
            "Epoch 70, Loss: 2.0854544639587402, Accuracy: 28.0000057220459\n",
            "Epoch 71, Loss: 2.150845766067505, Accuracy: 26.499998092651367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.0851588\n",
            "Epoch 72, Loss: 2.0851588249206543, Accuracy: 27.999996185302734\n",
            "Epoch 73, Loss: 2.1455488204956055, Accuracy: 26.833328247070312\n",
            "Epoch 74, Loss: 2.115501642227173, Accuracy: 25.833330154418945\n",
            "Epoch 75, Loss: 2.1307871341705322, Accuracy: 25.916667938232422\n",
            "Epoch 76, Loss: 2.121365785598755, Accuracy: 26.916667938232422\n",
            "Epoch 77, Loss: 2.085852861404419, Accuracy: 27.916669845581055\n",
            "Epoch 78, Loss: 2.10559344291687, Accuracy: 27.999996185302734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.0762696\n",
            "Epoch 79, Loss: 2.0762696266174316, Accuracy: 29.41667366027832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.070484\n",
            "Epoch 80, Loss: 2.070483922958374, Accuracy: 31.08333396911621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#number of classes\n",
        "num_way = num_ways[4] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[4]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[4] \n",
        "\n",
        "train_loss = tf.metrics.Mean(name='train_loss')\n",
        "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "num_epochs = 80\n",
        "num_episodes = 100\n",
        "save_path = \"./results/models/cifar100_train4.h5\"\n",
        "\n",
        "least_loss = {'least_loss': 100.00}\n",
        "\n",
        "@tf.function\n",
        "def loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "@tf.function\n",
        "def train_step(support, query):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  train_loss(loss)\n",
        "  train_acc(acc)\n",
        "\n",
        "@tf.function\n",
        "def val_step(loss_func, support, query):\n",
        "  loss, acc = loss_func(support, query)\n",
        "  val_loss(loss)\n",
        "  val_acc(acc)\n",
        "\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "    train_support, train_query = get_next_batch(train_images_split, train_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "    train_step(train_support, train_query)\n",
        "\n",
        "  cur_loss = train_loss.result().numpy()\n",
        "  if cur_loss < least_loss['least_loss']:\n",
        "      print(\"Saving new best model with loss: \", cur_loss)\n",
        "      least_loss['least_loss'] = cur_loss\n",
        "      model.save(save_path)\n",
        "      \n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
        "  print(template.format(epoch + 1, train_loss.result(), train_acc.result() * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FILHOD6qIlXt",
        "outputId": "42ea55ec-583f-41e9-bf57-d959fefacd7f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.577684\n",
            "Epoch 1, Loss: 2.577683925628662, Accuracy: 18.51111602783203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.415197\n",
            "Epoch 2, Loss: 2.4151968955993652, Accuracy: 22.066675186157227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.3830984\n",
            "Epoch 3, Loss: 2.3830983638763428, Accuracy: 23.155553817749023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.3598247\n",
            "Epoch 4, Loss: 2.3598246574401855, Accuracy: 23.822221755981445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.3494563\n",
            "Epoch 5, Loss: 2.349456310272217, Accuracy: 24.577783584594727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.2835336\n",
            "Epoch 6, Loss: 2.2835335731506348, Accuracy: 26.53333282470703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.2620926\n",
            "Epoch 7, Loss: 2.2620925903320312, Accuracy: 26.711118698120117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.226636\n",
            "Epoch 8, Loss: 2.2266359329223633, Accuracy: 27.600006103515625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.1874912\n",
            "Epoch 9, Loss: 2.1874911785125732, Accuracy: 29.0000057220459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.1567636\n",
            "Epoch 10, Loss: 2.1567635536193848, Accuracy: 30.533340454101562\n",
            "Epoch 11, Loss: 2.2123827934265137, Accuracy: 28.68889045715332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.1444788\n",
            "Epoch 12, Loss: 2.1444787979125977, Accuracy: 31.066665649414062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.125417\n",
            "Epoch 13, Loss: 2.1254169940948486, Accuracy: 31.022226333618164\n",
            "Epoch 14, Loss: 2.169867753982544, Accuracy: 30.200000762939453\n",
            "Epoch 15, Loss: 2.1572470664978027, Accuracy: 30.755558013916016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.071491\n",
            "Epoch 16, Loss: 2.071491003036499, Accuracy: 33.20000457763672\n",
            "Epoch 17, Loss: 2.079848289489746, Accuracy: 32.46666717529297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.0610602\n",
            "Epoch 18, Loss: 2.0610601902008057, Accuracy: 33.111114501953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.0414324\n",
            "Epoch 19, Loss: 2.0414323806762695, Accuracy: 34.51111602783203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.040805\n",
            "Epoch 20, Loss: 2.0408051013946533, Accuracy: 33.62223434448242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  2.0290878\n",
            "Epoch 21, Loss: 2.029087781906128, Accuracy: 34.488887786865234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.973367\n",
            "Epoch 22, Loss: 1.9733669757843018, Accuracy: 35.133331298828125\n",
            "Epoch 23, Loss: 2.033066749572754, Accuracy: 33.91111755371094\n",
            "Epoch 24, Loss: 2.030095338821411, Accuracy: 34.37778854370117\n",
            "Epoch 25, Loss: 2.0109148025512695, Accuracy: 35.022220611572266\n",
            "Epoch 26, Loss: 1.9792178869247437, Accuracy: 35.37777328491211\n",
            "Epoch 27, Loss: 1.9792355298995972, Accuracy: 35.733341217041016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.942353\n",
            "Epoch 28, Loss: 1.9423530101776123, Accuracy: 37.04444122314453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.9279337\n",
            "Epoch 29, Loss: 1.927933692932129, Accuracy: 37.95555114746094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.9217354\n",
            "Epoch 30, Loss: 1.921735405921936, Accuracy: 36.955543518066406\n",
            "Epoch 31, Loss: 1.9233492612838745, Accuracy: 37.844444274902344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.920174\n",
            "Epoch 32, Loss: 1.9201740026474, Accuracy: 36.51112365722656\n",
            "Epoch 33, Loss: 1.9266990423202515, Accuracy: 38.177772521972656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.8985637\n",
            "Epoch 34, Loss: 1.8985637426376343, Accuracy: 38.9111213684082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.8901492\n",
            "Epoch 35, Loss: 1.8901492357254028, Accuracy: 37.28889465332031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.8276126\n",
            "Epoch 36, Loss: 1.8276126384735107, Accuracy: 41.40000534057617\n",
            "Epoch 37, Loss: 1.8385341167449951, Accuracy: 40.66667175292969\n",
            "Epoch 38, Loss: 1.8712807893753052, Accuracy: 39.77778244018555\n",
            "Epoch 39, Loss: 1.8396127223968506, Accuracy: 39.266666412353516\n",
            "Epoch 40, Loss: 1.835196852684021, Accuracy: 39.622230529785156\n",
            "Epoch 41, Loss: 1.841609001159668, Accuracy: 40.155540466308594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.8107872\n",
            "Epoch 42, Loss: 1.8107872009277344, Accuracy: 40.31111526489258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.7781514\n",
            "Epoch 43, Loss: 1.7781513929367065, Accuracy: 41.79999542236328\n",
            "Epoch 44, Loss: 1.7877525091171265, Accuracy: 41.533329010009766\n",
            "Epoch 45, Loss: 1.7852718830108643, Accuracy: 41.24444580078125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.7765018\n",
            "Epoch 46, Loss: 1.7765017747879028, Accuracy: 42.4666633605957\n",
            "Epoch 47, Loss: 1.8009440898895264, Accuracy: 41.11111831665039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.7620605\n",
            "Epoch 48, Loss: 1.762060523033142, Accuracy: 42.26666259765625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.7481637\n",
            "Epoch 49, Loss: 1.7481637001037598, Accuracy: 42.60000991821289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.7209764\n",
            "Epoch 50, Loss: 1.7209763526916504, Accuracy: 43.9333381652832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.6796843\n",
            "Epoch 51, Loss: 1.6796842813491821, Accuracy: 44.577789306640625\n",
            "Epoch 52, Loss: 1.7078185081481934, Accuracy: 43.977783203125\n",
            "Epoch 53, Loss: 1.6839731931686401, Accuracy: 44.60000228881836\n",
            "Epoch 54, Loss: 1.6836190223693848, Accuracy: 44.53333282470703\n",
            "Epoch 55, Loss: 1.7169651985168457, Accuracy: 43.28889465332031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.6209385\n",
            "Epoch 56, Loss: 1.6209385395050049, Accuracy: 46.555564880371094\n",
            "Epoch 57, Loss: 1.6893141269683838, Accuracy: 44.0\n",
            "Epoch 58, Loss: 1.6480075120925903, Accuracy: 45.5777702331543\n",
            "Epoch 59, Loss: 1.6909575462341309, Accuracy: 45.5111083984375\n",
            "Epoch 60, Loss: 1.6401745080947876, Accuracy: 45.24443817138672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.6045467\n",
            "Epoch 61, Loss: 1.6045466661453247, Accuracy: 46.57777786254883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5997967\n",
            "Epoch 62, Loss: 1.5997966527938843, Accuracy: 48.0000114440918\n",
            "Epoch 63, Loss: 1.632612705230713, Accuracy: 46.75553894042969\n",
            "Epoch 64, Loss: 1.6269137859344482, Accuracy: 45.82222366333008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5956501\n",
            "Epoch 65, Loss: 1.59565007686615, Accuracy: 47.844451904296875\n",
            "Epoch 66, Loss: 1.6049013137817383, Accuracy: 46.80000686645508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5754285\n",
            "Epoch 67, Loss: 1.5754284858703613, Accuracy: 48.111106872558594\n",
            "Epoch 68, Loss: 1.5948917865753174, Accuracy: 47.57777786254883\n",
            "Epoch 69, Loss: 1.600175380706787, Accuracy: 47.377769470214844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5529767\n",
            "Epoch 70, Loss: 1.5529767274856567, Accuracy: 48.28888702392578\n",
            "Epoch 71, Loss: 1.5701156854629517, Accuracy: 48.31111145019531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5520837\n",
            "Epoch 72, Loss: 1.5520837306976318, Accuracy: 48.4666748046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5294867\n",
            "Epoch 73, Loss: 1.5294866561889648, Accuracy: 49.68889236450195\n",
            "Epoch 74, Loss: 1.5636084079742432, Accuracy: 48.20000076293945\n",
            "Epoch 75, Loss: 1.549952745437622, Accuracy: 47.88890075683594\n",
            "Epoch 76, Loss: 1.5760912895202637, Accuracy: 48.75555419921875\n",
            "Epoch 77, Loss: 1.5588434934616089, Accuracy: 48.53333282470703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.5241876\n",
            "Epoch 78, Loss: 1.5241875648498535, Accuracy: 50.20000457763672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving new best model with loss:  1.4927248\n",
            "Epoch 79, Loss: 1.4927247762680054, Accuracy: 50.488887786865234\n",
            "Epoch 80, Loss: 1.5349442958831787, Accuracy: 49.200008392333984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_path = \"./results/models/cifar100_train0.h5\"\n",
        "model.load(model_path)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[0]\n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[0]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[0] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "num_episodes = 1200\n",
        "\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "\n",
        "# Metrics to gather\n",
        "test_loss = tf.metrics.Mean(name='test_loss')\n",
        "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
        "\n",
        "def calc_loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "  test_support, test_query = get_next_batch(test_images, test_labels, num_way, num_shot, num_query, num_examples)\n",
        "  if (i_episode+1)%50 == 0: \n",
        "    print(\"Episode: \", i_episode + 1)\n",
        "  loss, acc = calc_loss(test_support, test_query)\n",
        "  test_loss(loss)\n",
        "  test_acc(acc)\n",
        "\n",
        "print(\"Loss: \", test_loss.result().numpy())\n",
        "print(\"Accuracy: \", test_acc.result().numpy() * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybKMJtz-U-By",
        "outputId": "6bce3372-42dc-463e-fa43-26bfd9ab48e2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Episode:  50\n",
            "Episode:  100\n",
            "Episode:  150\n",
            "Episode:  200\n",
            "Episode:  250\n",
            "Episode:  300\n",
            "Episode:  350\n",
            "Episode:  400\n",
            "Episode:  450\n",
            "Episode:  500\n",
            "Episode:  550\n",
            "Episode:  600\n",
            "Episode:  650\n",
            "Episode:  700\n",
            "Episode:  750\n",
            "Episode:  800\n",
            "Episode:  850\n",
            "Episode:  900\n",
            "Episode:  950\n",
            "Episode:  1000\n",
            "Episode:  1050\n",
            "Episode:  1100\n",
            "Episode:  1150\n",
            "Episode:  1200\n",
            "Loss:  1.6093625\n",
            "Accuracy:  35.89663207530975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"./results/models/cifar100_train1.h5\"\n",
        "model.load(model_path)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[1]\n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[1]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[1] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "num_episodes = 1200\n",
        "\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "\n",
        "# Metrics to gather\n",
        "test_loss = tf.metrics.Mean(name='test_loss')\n",
        "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
        "\n",
        "def calc_loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "  test_support, test_query = get_next_batch(test_images, test_labels, num_way, num_shot, num_query, num_examples)\n",
        "  if (i_episode+1)%50 == 0: \n",
        "    print(\"Episode: \", i_episode + 1)\n",
        "  loss, acc = calc_loss(test_support, test_query)\n",
        "  test_loss(loss)\n",
        "  test_acc(acc)\n",
        "\n",
        "print(\"Loss: \", test_loss.result().numpy())\n",
        "print(\"Accuracy: \", test_acc.result().numpy() * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33Vs5c7LkTRi",
        "outputId": "5cf401d9-a703-4772-c441-661c7617f1bf"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Episode:  50\n",
            "Episode:  100\n",
            "Episode:  150\n",
            "Episode:  200\n",
            "Episode:  250\n",
            "Episode:  300\n",
            "Episode:  350\n",
            "Episode:  400\n",
            "Episode:  450\n",
            "Episode:  500\n",
            "Episode:  550\n",
            "Episode:  600\n",
            "Episode:  650\n",
            "Episode:  700\n",
            "Episode:  750\n",
            "Episode:  800\n",
            "Episode:  850\n",
            "Episode:  900\n",
            "Episode:  950\n",
            "Episode:  1000\n",
            "Episode:  1050\n",
            "Episode:  1100\n",
            "Episode:  1150\n",
            "Episode:  1200\n",
            "Loss:  1.6093297\n",
            "Accuracy:  29.516687989234924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"./results/models/cifar100_train2.h5\"\n",
        "model.load(model_path)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[2]\n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[2]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[2] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "num_episodes = 1200\n",
        "\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "\n",
        "# Metrics to gather\n",
        "test_loss = tf.metrics.Mean(name='test_loss')\n",
        "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
        "\n",
        "def calc_loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "  test_support, test_query = get_next_batch(test_images, test_labels, num_way, num_shot, num_query, num_examples)\n",
        "  if (i_episode+1)%50 == 0: \n",
        "    print(\"Episode: \", i_episode + 1)\n",
        "  loss, acc = calc_loss(test_support, test_query)\n",
        "  test_loss(loss)\n",
        "  test_acc(acc)\n",
        "\n",
        "print(\"Loss: \", test_loss.result().numpy())\n",
        "print(\"Accuracy: \", test_acc.result().numpy() * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksiuhTGzkTsF",
        "outputId": "40ba3be4-9e56-4dd3-8736-56b737957f54"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Episode:  50\n",
            "Episode:  100\n",
            "Episode:  150\n",
            "Episode:  200\n",
            "Episode:  250\n",
            "Episode:  300\n",
            "Episode:  350\n",
            "Episode:  400\n",
            "Episode:  450\n",
            "Episode:  500\n",
            "Episode:  550\n",
            "Episode:  600\n",
            "Episode:  650\n",
            "Episode:  700\n",
            "Episode:  750\n",
            "Episode:  800\n",
            "Episode:  850\n",
            "Episode:  900\n",
            "Episode:  950\n",
            "Episode:  1000\n",
            "Episode:  1050\n",
            "Episode:  1100\n",
            "Episode:  1150\n",
            "Episode:  1200\n",
            "Loss:  2.4847746\n",
            "Accuracy:  21.73885405063629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"./results/models/cifar100_train3.h5\"\n",
        "model.load(model_path)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[3]\n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[3]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[3] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "num_episodes = 1200\n",
        "\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "\n",
        "# Metrics to gather\n",
        "test_loss = tf.metrics.Mean(name='test_loss')\n",
        "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
        "\n",
        "def calc_loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "  test_support, test_query = get_next_batch(test_images, test_labels, num_way, num_shot, num_query, num_examples)\n",
        "  if (i_episode+1)%50 == 0: \n",
        "    print(\"Episode: \", i_episode + 1)\n",
        "  loss, acc = calc_loss(test_support, test_query)\n",
        "  test_loss(loss)\n",
        "  test_acc(acc)\n",
        "\n",
        "print(\"Loss: \", test_loss.result().numpy())\n",
        "print(\"Accuracy: \", test_acc.result().numpy() * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njde06MMkUFn",
        "outputId": "92457ca5-8c2b-46d7-fc16-1ebc46418e44"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Episode:  50\n",
            "Episode:  100\n",
            "Episode:  150\n",
            "Episode:  200\n",
            "Episode:  250\n",
            "Episode:  300\n",
            "Episode:  350\n",
            "Episode:  400\n",
            "Episode:  450\n",
            "Episode:  500\n",
            "Episode:  550\n",
            "Episode:  600\n",
            "Episode:  650\n",
            "Episode:  700\n",
            "Episode:  750\n",
            "Episode:  800\n",
            "Episode:  850\n",
            "Episode:  900\n",
            "Episode:  950\n",
            "Episode:  1000\n",
            "Episode:  1050\n",
            "Episode:  1100\n",
            "Episode:  1150\n",
            "Episode:  1200\n",
            "Loss:  2.4847887\n",
            "Accuracy:  15.819448232650757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"./results/models/cifar100_train4.h5\"\n",
        "model.load(model_path)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[4]\n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[4]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[4] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "num_episodes = 1200\n",
        "\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "\n",
        "# Metrics to gather\n",
        "test_loss = tf.metrics.Mean(name='test_loss')\n",
        "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
        "\n",
        "def calc_loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "  test_support, test_query = get_next_batch(test_images, test_labels, num_way, num_shot, num_query, num_examples)\n",
        "  if (i_episode+1)%50 == 0: \n",
        "    print(\"Episode: \", i_episode + 1)\n",
        "  loss, acc = calc_loss(test_support, test_query)\n",
        "  test_loss(loss)\n",
        "  test_acc(acc)\n",
        "\n",
        "print(\"Loss: \", test_loss.result().numpy())\n",
        "print(\"Accuracy: \", test_acc.result().numpy() * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kteFHAnIkUfp",
        "outputId": "abc3e452-2c28-4730-9aee-cfa5c4c2dcb1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Episode:  50\n",
            "Episode:  100\n",
            "Episode:  150\n",
            "Episode:  200\n",
            "Episode:  250\n",
            "Episode:  300\n",
            "Episode:  350\n",
            "Episode:  400\n",
            "Episode:  450\n",
            "Episode:  500\n",
            "Episode:  550\n",
            "Episode:  600\n",
            "Episode:  650\n",
            "Episode:  700\n",
            "Episode:  750\n",
            "Episode:  800\n",
            "Episode:  850\n",
            "Episode:  900\n",
            "Episode:  950\n",
            "Episode:  1000\n",
            "Episode:  1050\n",
            "Episode:  1100\n",
            "Episode:  1150\n",
            "Episode:  1200\n",
            "Loss:  2.7078836\n",
            "Accuracy:  17.335160076618195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now adding reptile to this\n",
        "meta_step_size = 0.25\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[0] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[0]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[0] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "eval_iters = 20\n",
        "eval_interval = 4\n",
        "least_loss = {'least_loss': 100.00}\n",
        "\n",
        "train_loss = tf.metrics.Mean(name='train_loss')\n",
        "val_loss = tf.metrics.Mean(name='val_loss')\n",
        "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
        "val_acc = tf.metrics.Mean(name='val_accuracy')\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "optimizer_adam = tf.keras.optimizers.Adam(0.001)\n",
        "optimizer_sgd = tf.keras.optimizers.SGD(0.001)\n",
        "\n",
        "num_epochs = 81\n",
        "num_episodes = 100\n",
        "save_path = \"./results/models/cifar100_train_reptile0.h5\"\n",
        "\n",
        "@tf.function\n",
        "def loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "@tf.function\n",
        "def train_step(support, query, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  \n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_acc(acc)\n",
        "  \n",
        "\n",
        "@tf.function\n",
        "def val_step(support, query, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  \n",
        "  val_loss(loss)\n",
        "  val_acc(acc)\n",
        "\n",
        "\n",
        "least_loss = {'least_loss': 100.00}\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss.reset_states()\n",
        "  val_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "  val_acc.reset_states()\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "    frac_done = episode / num_episodes\n",
        "    cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
        "    train_support, train_query = get_next_batch(train_images_split, train_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "    model = Prototypical(train_support, train_query, img_width, img_height, channels)\n",
        "    model.call(train_support, train_query)\n",
        "    old_weights = model.get_weights()\n",
        "    train_step(train_support, train_query, optimizer_adam)\n",
        "    new_weights = model.get_weights()\n",
        "\n",
        "    for part_weight in range(len(new_weights)):\n",
        "        new_weights[part_weight] = old_weights[part_weight] + (\n",
        "            (new_weights[part_weight] - old_weights[part_weight]) * cur_meta_step_size\n",
        "        )\n",
        "\n",
        "    model.set_weights(new_weights)\n",
        "    if epoch % eval_interval == 0:\n",
        "      eval_support, eval_query = get_next_batch(val_images_split, val_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "      old_vars = model.get_weights()\n",
        "      val_step(eval_support, eval_query, optimizer_sgd)\n",
        "      model.set_weights(old_vars)\n",
        "      \n",
        "  cur_loss = val_loss.result().numpy()\n",
        "\n",
        "  if (epoch % eval_interval == 0):\n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, ' \\\n",
        "                  'Val Loss: {}, Val Accuracy: {}'\n",
        "    print(template.format(epoch + 1, train_loss.result(), train_acc.result() * 100, val_loss.result(),\n",
        "                            val_acc.result() * 100))\n",
        "    if cur_loss < least_loss['least_loss']:\n",
        "      print(\"Saving new best model with loss: \", cur_loss)\n",
        "      least_loss['least_loss'] = cur_loss\n",
        "      model.save(save_path)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec21337-c44f-49d8-8e10-8b1311222dd1",
        "id": "cxBEkIU4rKUU"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.5036752223968506, Accuracy: 37.71999740600586, Val Loss: 1.487634539604187, Val Accuracy: 38.68000411987305\n",
            "Saving new best model with loss:  1.4876345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 1.355270504951477, Accuracy: 44.480003356933594, Val Loss: 1.3263978958129883, Val Accuracy: 44.71999740600586\n",
            "Saving new best model with loss:  1.3263979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 1.2907603979110718, Accuracy: 46.400001525878906, Val Loss: 1.3091789484024048, Val Accuracy: 46.31999588012695\n",
            "Saving new best model with loss:  1.309179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 1.2424434423446655, Accuracy: 49.44001007080078, Val Loss: 1.2612682580947876, Val Accuracy: 51.5999870300293\n",
            "Saving new best model with loss:  1.2612683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 1.158989667892456, Accuracy: 54.040000915527344, Val Loss: 1.1633973121643066, Val Accuracy: 53.480003356933594\n",
            "Saving new best model with loss:  1.1633973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Loss: 1.1325095891952515, Accuracy: 55.07999801635742, Val Loss: 1.150446891784668, Val Accuracy: 53.799991607666016\n",
            "Saving new best model with loss:  1.1504469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Loss: 1.0792624950408936, Accuracy: 56.720001220703125, Val Loss: 1.1268529891967773, Val Accuracy: 55.91999435424805\n",
            "Saving new best model with loss:  1.126853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Loss: 1.031113862991333, Accuracy: 59.159996032714844, Val Loss: 1.1022181510925293, Val Accuracy: 55.799991607666016\n",
            "Saving new best model with loss:  1.1022182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33, Loss: 1.0642895698547363, Accuracy: 55.44001007080078, Val Loss: 1.0951142311096191, Val Accuracy: 56.75999069213867\n",
            "Saving new best model with loss:  1.0951142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37, Loss: 1.0423496961593628, Accuracy: 57.79999923706055, Val Loss: 1.0165902376174927, Val Accuracy: 59.40000534057617\n",
            "Saving new best model with loss:  1.0165902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41, Loss: 0.9918379783630371, Accuracy: 60.9999885559082, Val Loss: 1.0001436471939087, Val Accuracy: 60.07999038696289\n",
            "Saving new best model with loss:  1.0001436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Loss: 0.958865761756897, Accuracy: 62.48001480102539, Val Loss: 0.9679837226867676, Val Accuracy: 60.56001281738281\n",
            "Saving new best model with loss:  0.9679837\n",
            "Epoch 49, Loss: 0.961426317691803, Accuracy: 62.1199836730957, Val Loss: 0.9905039072036743, Val Accuracy: 59.839988708496094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53, Loss: 0.9820749759674072, Accuracy: 60.880001068115234, Val Loss: 0.9453576803207397, Val Accuracy: 61.839996337890625\n",
            "Saving new best model with loss:  0.9453577\n",
            "Epoch 57, Loss: 0.9351054430007935, Accuracy: 63.59999084472656, Val Loss: 0.9470184445381165, Val Accuracy: 63.39999008178711\n",
            "Epoch 61, Loss: 0.9767304062843323, Accuracy: 61.11998748779297, Val Loss: 0.9508388042449951, Val Accuracy: 63.239990234375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65, Loss: 0.8912419080734253, Accuracy: 65.6399917602539, Val Loss: 0.9266886711120605, Val Accuracy: 64.43998718261719\n",
            "Saving new best model with loss:  0.9266887\n",
            "Epoch 69, Loss: 0.8577409386634827, Accuracy: 66.95999908447266, Val Loss: 0.9473784565925598, Val Accuracy: 62.43999481201172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73, Loss: 0.8820846676826477, Accuracy: 64.55999755859375, Val Loss: 0.8714672327041626, Val Accuracy: 65.84000396728516\n",
            "Saving new best model with loss:  0.87146723\n",
            "Epoch 77, Loss: 0.8727816939353943, Accuracy: 65.0, Val Loss: 0.893456220626831, Val Accuracy: 64.8799819946289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81, Loss: 0.8621225953102112, Accuracy: 65.6399917602539, Val Loss: 0.8505910634994507, Val Accuracy: 67.15997314453125\n",
            "Saving new best model with loss:  0.85059106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now adding reptile to this\n",
        "meta_step_size = 0.25\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[1] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[1]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[1] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "eval_iters = 20\n",
        "eval_interval = 4\n",
        "least_loss = {'least_loss': 100.00}\n",
        "\n",
        "train_loss = tf.metrics.Mean(name='train_loss')\n",
        "val_loss = tf.metrics.Mean(name='val_loss')\n",
        "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
        "val_acc = tf.metrics.Mean(name='val_accuracy')\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "optimizer_adam = tf.keras.optimizers.Adam(0.001)\n",
        "optimizer_sgd = tf.keras.optimizers.SGD(0.001)\n",
        "\n",
        "num_epochs = 81\n",
        "num_episodes = 100\n",
        "save_path = \"./results/models/cifar100_train_reptile1.h5\"\n",
        "\n",
        "@tf.function\n",
        "def loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "@tf.function\n",
        "def train_step(support, query, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  \n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_acc(acc)\n",
        "  \n",
        "\n",
        "@tf.function\n",
        "def val_step(support, query, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  \n",
        "  val_loss(loss)\n",
        "  val_acc(acc)\n",
        "\n",
        "\n",
        "least_loss = {'least_loss': 100.00}\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss.reset_states()\n",
        "  val_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "  val_acc.reset_states()\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "    frac_done = episode / num_episodes\n",
        "    cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
        "    train_support, train_query = get_next_batch(train_images_split, train_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "    model = Prototypical(train_support, train_query, img_width, img_height, channels)\n",
        "    model.call(train_support, train_query)\n",
        "    old_weights = model.get_weights()\n",
        "    train_step(train_support, train_query, optimizer_adam)\n",
        "    new_weights = model.get_weights()\n",
        "\n",
        "    for part_weight in range(len(new_weights)):\n",
        "        new_weights[part_weight] = old_weights[part_weight] + (\n",
        "            (new_weights[part_weight] - old_weights[part_weight]) * cur_meta_step_size\n",
        "        )\n",
        "\n",
        "    model.set_weights(new_weights)\n",
        "    if epoch % eval_interval == 0:\n",
        "      eval_support, eval_query = get_next_batch(val_images_split, val_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "      old_vars = model.get_weights()\n",
        "      val_step(eval_support, eval_query, optimizer_sgd)\n",
        "      model.set_weights(old_vars)\n",
        "      \n",
        "  cur_loss = val_loss.result().numpy()\n",
        "\n",
        "  if (epoch % eval_interval == 0):\n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, ' \\\n",
        "                  'Val Loss: {}, Val Accuracy: {}'\n",
        "    print(template.format(epoch + 1, train_loss.result(), train_acc.result() * 100, val_loss.result(),\n",
        "                            val_acc.result() * 100))\n",
        "    if cur_loss < least_loss['least_loss']:\n",
        "      print(\"Saving new best model with loss: \", cur_loss)\n",
        "      least_loss['least_loss'] = cur_loss\n",
        "      model.save(save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDZJF-lJoTo_",
        "outputId": "c35169d8-c47e-4b8d-b205-fbadc92111a7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.5697510242462158, Accuracy: 27.399999618530273, Val Loss: 1.5818787813186646, Val Accuracy: 28.600004196166992\n",
            "Saving new best model with loss:  1.5818788\n",
            "Epoch 5, Loss: 1.5867465734481812, Accuracy: 31.400009155273438, Val Loss: 1.5901356935501099, Val Accuracy: 27.200008392333984\n",
            "Epoch 9, Loss: 1.5995639562606812, Accuracy: 28.80000114440918, Val Loss: 1.5856050252914429, Val Accuracy: 26.800003051757812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 1.5422909259796143, Accuracy: 28.600004196166992, Val Loss: 1.5717967748641968, Val Accuracy: 32.599998474121094\n",
            "Saving new best model with loss:  1.5717968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 1.5256119966506958, Accuracy: 34.19999694824219, Val Loss: 1.5499838590621948, Val Accuracy: 30.60000228881836\n",
            "Saving new best model with loss:  1.5499839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Loss: 1.5371222496032715, Accuracy: 33.80000686645508, Val Loss: 1.5000828504562378, Val Accuracy: 33.000003814697266\n",
            "Saving new best model with loss:  1.5000829\n",
            "Epoch 25, Loss: 1.5155394077301025, Accuracy: 34.80000686645508, Val Loss: 1.5259110927581787, Val Accuracy: 33.200008392333984\n",
            "Epoch 29, Loss: 1.5063153505325317, Accuracy: 35.800010681152344, Val Loss: 1.5002636909484863, Val Accuracy: 34.80002212524414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33, Loss: 1.5029772520065308, Accuracy: 36.79999542236328, Val Loss: 1.4745304584503174, Val Accuracy: 36.000003814697266\n",
            "Saving new best model with loss:  1.4745305\n",
            "Epoch 37, Loss: 1.4749531745910645, Accuracy: 38.00000762939453, Val Loss: 1.5237239599227905, Val Accuracy: 33.0\n",
            "Epoch 41, Loss: 1.5342164039611816, Accuracy: 33.80000686645508, Val Loss: 1.502539038658142, Val Accuracy: 32.40000915527344\n",
            "Epoch 45, Loss: 1.5148766040802002, Accuracy: 34.40000915527344, Val Loss: 1.4815673828125, Val Accuracy: 36.0\n",
            "Epoch 49, Loss: 1.4361766576766968, Accuracy: 39.200008392333984, Val Loss: 1.520632266998291, Val Accuracy: 33.80000686645508\n",
            "Epoch 53, Loss: 1.4851855039596558, Accuracy: 35.40000915527344, Val Loss: 1.4907891750335693, Val Accuracy: 36.00000762939453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57, Loss: 1.451245903968811, Accuracy: 37.80002212524414, Val Loss: 1.4605594873428345, Val Accuracy: 37.800010681152344\n",
            "Saving new best model with loss:  1.4605595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61, Loss: 1.4699108600616455, Accuracy: 37.00000762939453, Val Loss: 1.4372657537460327, Val Accuracy: 38.599998474121094\n",
            "Saving new best model with loss:  1.4372658\n",
            "Epoch 65, Loss: 1.4307385683059692, Accuracy: 36.600006103515625, Val Loss: 1.4549566507339478, Val Accuracy: 34.800010681152344\n",
            "Epoch 69, Loss: 1.4201173782348633, Accuracy: 38.200008392333984, Val Loss: 1.5024298429489136, Val Accuracy: 34.40000915527344\n",
            "Epoch 73, Loss: 1.441933274269104, Accuracy: 36.400001525878906, Val Loss: 1.4385768175125122, Val Accuracy: 40.40000534057617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77, Loss: 1.385218620300293, Accuracy: 41.399993896484375, Val Loss: 1.4073421955108643, Val Accuracy: 40.600006103515625\n",
            "Saving new best model with loss:  1.4073422\n",
            "Epoch 81, Loss: 1.4474859237670898, Accuracy: 36.80000305175781, Val Loss: 1.4518589973449707, Val Accuracy: 37.20001220703125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now adding reptile to this\n",
        "meta_step_size = 0.25\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[2] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[2]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[2] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "eval_iters = 20\n",
        "eval_interval = 4\n",
        "least_loss = {'least_loss': 100.00}\n",
        "\n",
        "train_loss = tf.metrics.Mean(name='train_loss')\n",
        "val_loss = tf.metrics.Mean(name='val_loss')\n",
        "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
        "val_acc = tf.metrics.Mean(name='val_accuracy')\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "optimizer_adam = tf.keras.optimizers.Adam(0.001)\n",
        "optimizer_sgd = tf.keras.optimizers.SGD(0.001)\n",
        "\n",
        "num_epochs = 81\n",
        "num_episodes = 100\n",
        "save_path = \"./results/models/cifar100_train_reptile2.h5\"\n",
        "\n",
        "@tf.function\n",
        "def loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "@tf.function\n",
        "def train_step(support, query, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  \n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_acc(acc)\n",
        "  \n",
        "\n",
        "@tf.function\n",
        "def val_step(support, query, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  \n",
        "  val_loss(loss)\n",
        "  val_acc(acc)\n",
        "\n",
        "\n",
        "least_loss = {'least_loss': 100.00}\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss.reset_states()\n",
        "  val_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "  val_acc.reset_states()\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "    frac_done = episode / num_episodes\n",
        "    cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
        "    train_support, train_query = get_next_batch(train_images_split, train_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "    model = Prototypical(train_support, train_query, img_width, img_height, channels)\n",
        "    model.call(train_support, train_query)\n",
        "    old_weights = model.get_weights()\n",
        "    train_step(train_support, train_query, optimizer_adam)\n",
        "    new_weights = model.get_weights()\n",
        "\n",
        "    for part_weight in range(len(new_weights)):\n",
        "        new_weights[part_weight] = old_weights[part_weight] + (\n",
        "            (new_weights[part_weight] - old_weights[part_weight]) * cur_meta_step_size\n",
        "        )\n",
        "\n",
        "    model.set_weights(new_weights)\n",
        "    if epoch % eval_interval == 0:\n",
        "      eval_support, eval_query = get_next_batch(val_images_split, val_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "      old_vars = model.get_weights()\n",
        "      val_step(eval_support, eval_query, optimizer_sgd)\n",
        "      model.set_weights(old_vars)\n",
        "      \n",
        "  cur_loss = val_loss.result().numpy()\n",
        "\n",
        "  if (epoch % eval_interval == 0):\n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, ' \\\n",
        "                  'Val Loss: {}, Val Accuracy: {}'\n",
        "    print(template.format(epoch + 1, train_loss.result(), train_acc.result() * 100, val_loss.result(),\n",
        "                            val_acc.result() * 100))\n",
        "    if cur_loss < least_loss['least_loss']:\n",
        "      print(\"Saving new best model with loss: \", cur_loss)\n",
        "      least_loss['least_loss'] = cur_loss\n",
        "      model.save(save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcq3hGMqoUDC",
        "outputId": "b101fe80-615c-4943-cad1-163a318a922c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.2839200496673584, Accuracy: 22.65000343322754, Val Loss: 2.293394088745117, Val Accuracy: 21.96666145324707\n",
            "Saving new best model with loss:  2.293394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 2.033641815185547, Accuracy: 32.366676330566406, Val Loss: 2.003223180770874, Val Accuracy: 32.58333206176758\n",
            "Saving new best model with loss:  2.0032232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 1.8424928188323975, Accuracy: 37.58333206176758, Val Loss: 1.8990182876586914, Val Accuracy: 35.73332977294922\n",
            "Saving new best model with loss:  1.8990183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 1.8099616765975952, Accuracy: 39.250003814697266, Val Loss: 1.7791258096694946, Val Accuracy: 39.250003814697266\n",
            "Saving new best model with loss:  1.7791258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 1.756499171257019, Accuracy: 40.75000762939453, Val Loss: 1.751427173614502, Val Accuracy: 40.883338928222656\n",
            "Saving new best model with loss:  1.7514272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Loss: 1.7022833824157715, Accuracy: 42.56666946411133, Val Loss: 1.6804732084274292, Val Accuracy: 43.00000762939453\n",
            "Saving new best model with loss:  1.6804732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Loss: 1.6464959383010864, Accuracy: 45.36667251586914, Val Loss: 1.6430691480636597, Val Accuracy: 44.14999771118164\n",
            "Saving new best model with loss:  1.6430691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Loss: 1.5493345260620117, Accuracy: 48.35000228881836, Val Loss: 1.5725502967834473, Val Accuracy: 47.249996185302734\n",
            "Saving new best model with loss:  1.5725503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33, Loss: 1.5147523880004883, Accuracy: 47.816673278808594, Val Loss: 1.5692013502120972, Val Accuracy: 47.583351135253906\n",
            "Saving new best model with loss:  1.5692014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37, Loss: 1.5054744482040405, Accuracy: 48.350006103515625, Val Loss: 1.4993386268615723, Val Accuracy: 48.850013732910156\n",
            "Saving new best model with loss:  1.4993386\n",
            "Epoch 41, Loss: 1.4150205850601196, Accuracy: 52.16667175292969, Val Loss: 1.5045398473739624, Val Accuracy: 49.64999008178711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Loss: 1.3818352222442627, Accuracy: 52.64999771118164, Val Loss: 1.4267359972000122, Val Accuracy: 51.533329010009766\n",
            "Saving new best model with loss:  1.426736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49, Loss: 1.3697017431259155, Accuracy: 53.549991607666016, Val Loss: 1.3956679105758667, Val Accuracy: 52.866668701171875\n",
            "Saving new best model with loss:  1.3956679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53, Loss: 1.2925093173980713, Accuracy: 55.483333587646484, Val Loss: 1.3433173894882202, Val Accuracy: 53.683326721191406\n",
            "Saving new best model with loss:  1.3433174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57, Loss: 1.2926892042160034, Accuracy: 55.1833381652832, Val Loss: 1.3181216716766357, Val Accuracy: 55.366661071777344\n",
            "Saving new best model with loss:  1.3181217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61, Loss: 1.2391473054885864, Accuracy: 57.06666564941406, Val Loss: 1.311784029006958, Val Accuracy: 55.01666259765625\n",
            "Saving new best model with loss:  1.311784\n",
            "Epoch 65, Loss: 1.2048101425170898, Accuracy: 59.41665267944336, Val Loss: 1.3411014080047607, Val Accuracy: 54.73332977294922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69, Loss: 1.2312438488006592, Accuracy: 58.26667404174805, Val Loss: 1.2838919162750244, Val Accuracy: 57.383338928222656\n",
            "Saving new best model with loss:  1.2838919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73, Loss: 1.1564967632293701, Accuracy: 60.96665954589844, Val Loss: 1.2761965990066528, Val Accuracy: 56.45000457763672\n",
            "Saving new best model with loss:  1.2761966\n",
            "Epoch 77, Loss: 1.1752430200576782, Accuracy: 60.23332595825195, Val Loss: 1.3342154026031494, Val Accuracy: 54.3833122253418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81, Loss: 1.1459014415740967, Accuracy: 60.966651916503906, Val Loss: 1.2283598184585571, Val Accuracy: 57.93333053588867\n",
            "Saving new best model with loss:  1.2283598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now adding reptile to this\n",
        "meta_step_size = 0.25\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[3] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[3]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[3] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "eval_iters = 20\n",
        "eval_interval = 4\n",
        "least_loss = {'least_loss': 100.00}\n",
        "\n",
        "train_loss = tf.metrics.Mean(name='train_loss')\n",
        "val_loss = tf.metrics.Mean(name='val_loss')\n",
        "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
        "val_acc = tf.metrics.Mean(name='val_accuracy')\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "optimizer_adam = tf.keras.optimizers.Adam(0.001)\n",
        "optimizer_sgd = tf.keras.optimizers.SGD(0.001)\n",
        "\n",
        "num_epochs = 81\n",
        "num_episodes = 100\n",
        "save_path = \"./results/models/cifar100_train_reptile3.h5\"\n",
        "\n",
        "@tf.function\n",
        "def loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "@tf.function\n",
        "def train_step(support, query, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  \n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_acc(acc)\n",
        "  \n",
        "\n",
        "@tf.function\n",
        "def val_step(support, query, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  \n",
        "  val_loss(loss)\n",
        "  val_acc(acc)\n",
        "\n",
        "\n",
        "least_loss = {'least_loss': 100.00}\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss.reset_states()\n",
        "  val_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "  val_acc.reset_states()\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "    frac_done = episode / num_episodes\n",
        "    cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
        "    train_support, train_query = get_next_batch(train_images_split, train_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "    model = Prototypical(train_support, train_query, img_width, img_height, channels)\n",
        "    model.call(train_support, train_query)\n",
        "    old_weights = model.get_weights()\n",
        "    train_step(train_support, train_query, optimizer_adam)\n",
        "    new_weights = model.get_weights()\n",
        "\n",
        "    for part_weight in range(len(new_weights)):\n",
        "        new_weights[part_weight] = old_weights[part_weight] + (\n",
        "            (new_weights[part_weight] - old_weights[part_weight]) * cur_meta_step_size\n",
        "        )\n",
        "\n",
        "    model.set_weights(new_weights)\n",
        "    if epoch % eval_interval == 0:\n",
        "      eval_support, eval_query = get_next_batch(val_images_split, val_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "      old_vars = model.get_weights()\n",
        "      val_step(eval_support, eval_query, optimizer_sgd)\n",
        "      model.set_weights(old_vars)\n",
        "      \n",
        "  cur_loss = val_loss.result().numpy()\n",
        "\n",
        "  if (epoch % eval_interval == 0):\n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, ' \\\n",
        "                  'Val Loss: {}, Val Accuracy: {}'\n",
        "    print(template.format(epoch + 1, train_loss.result(), train_acc.result() * 100, val_loss.result(),\n",
        "                            val_acc.result() * 100))\n",
        "    if cur_loss < least_loss['least_loss']:\n",
        "      print(\"Saving new best model with loss: \", cur_loss)\n",
        "      least_loss['least_loss'] = cur_loss\n",
        "      model.save(save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI_uYQx6oUeI",
        "outputId": "e12651d4-6e8f-4b1c-e747-225dbc98c261"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.448282241821289, Accuracy: 16.16666603088379, Val Loss: 2.4489617347717285, Val Accuracy: 14.916669845581055\n",
            "Saving new best model with loss:  2.4489617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 2.415513277053833, Accuracy: 17.83333396911621, Val Loss: 2.384927749633789, Val Accuracy: 18.750001907348633\n",
            "Saving new best model with loss:  2.3849277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 2.3516101837158203, Accuracy: 18.58332633972168, Val Loss: 2.3741040229797363, Val Accuracy: 18.333330154418945\n",
            "Saving new best model with loss:  2.374104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 2.307431936264038, Accuracy: 19.666664123535156, Val Loss: 2.3321619033813477, Val Accuracy: 20.666664123535156\n",
            "Saving new best model with loss:  2.332162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 2.320847749710083, Accuracy: 20.666664123535156, Val Loss: 2.3157408237457275, Val Accuracy: 20.500003814697266\n",
            "Saving new best model with loss:  2.3157408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Loss: 2.313309669494629, Accuracy: 19.08333396911621, Val Loss: 2.2961111068725586, Val Accuracy: 20.666675567626953\n",
            "Saving new best model with loss:  2.296111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Loss: 2.309081792831421, Accuracy: 22.166662216186523, Val Loss: 2.2732789516448975, Val Accuracy: 20.916664123535156\n",
            "Saving new best model with loss:  2.273279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Loss: 2.262791872024536, Accuracy: 24.916671752929688, Val Loss: 2.263408899307251, Val Accuracy: 22.583330154418945\n",
            "Saving new best model with loss:  2.263409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33, Loss: 2.2497386932373047, Accuracy: 23.333330154418945, Val Loss: 2.222459554672241, Val Accuracy: 23.166669845581055\n",
            "Saving new best model with loss:  2.2224596\n",
            "Epoch 37, Loss: 2.2525789737701416, Accuracy: 23.66666603088379, Val Loss: 2.2501654624938965, Val Accuracy: 22.000003814697266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41, Loss: 2.187608003616333, Accuracy: 25.916667938232422, Val Loss: 2.218153715133667, Val Accuracy: 23.583330154418945\n",
            "Saving new best model with loss:  2.2181537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Loss: 2.1859357357025146, Accuracy: 26.916671752929688, Val Loss: 2.20066237449646, Val Accuracy: 22.916664123535156\n",
            "Saving new best model with loss:  2.2006624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49, Loss: 2.1870641708374023, Accuracy: 24.666671752929688, Val Loss: 2.171717882156372, Val Accuracy: 25.08333396911621\n",
            "Saving new best model with loss:  2.171718\n",
            "Epoch 53, Loss: 2.180462121963501, Accuracy: 25.833330154418945, Val Loss: 2.1806480884552, Val Accuracy: 24.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57, Loss: 2.12676739692688, Accuracy: 28.08333396911621, Val Loss: 2.163832664489746, Val Accuracy: 26.083330154418945\n",
            "Saving new best model with loss:  2.1638327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61, Loss: 2.0993192195892334, Accuracy: 27.91666603088379, Val Loss: 2.1471102237701416, Val Accuracy: 28.500001907348633\n",
            "Saving new best model with loss:  2.1471102\n",
            "Epoch 65, Loss: 2.097226142883301, Accuracy: 27.166664123535156, Val Loss: 2.159135341644287, Val Accuracy: 25.333332061767578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69, Loss: 2.10117244720459, Accuracy: 28.166671752929688, Val Loss: 2.1368324756622314, Val Accuracy: 26.750003814697266\n",
            "Saving new best model with loss:  2.1368325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73, Loss: 2.102193832397461, Accuracy: 28.666664123535156, Val Loss: 2.0990495681762695, Val Accuracy: 28.916667938232422\n",
            "Saving new best model with loss:  2.0990496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77, Loss: 2.064854860305786, Accuracy: 29.416667938232422, Val Loss: 2.086606740951538, Val Accuracy: 27.916664123535156\n",
            "Saving new best model with loss:  2.0866067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81, Loss: 2.0389630794525146, Accuracy: 31.333335876464844, Val Loss: 2.076486587524414, Val Accuracy: 27.416667938232422\n",
            "Saving new best model with loss:  2.0764866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now adding reptile to this\n",
        "meta_step_size = 0.25\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[4] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[4]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[4] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "eval_iters = 20\n",
        "eval_interval = 4\n",
        "least_loss = {'least_loss': 100.00}\n",
        "\n",
        "train_loss = tf.metrics.Mean(name='train_loss')\n",
        "val_loss = tf.metrics.Mean(name='val_loss')\n",
        "train_acc = tf.metrics.Mean(name='train_accuracy')\n",
        "val_acc = tf.metrics.Mean(name='val_accuracy')\n",
        "support = np.zeros([num_way, num_shot, img_width, img_height, channels], dtype=np.float32)\n",
        "query = np.zeros([num_way, num_query, img_height, channels], dtype=np.float32)\n",
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "optimizer_adam = tf.keras.optimizers.Adam(0.001)\n",
        "optimizer_sgd = tf.keras.optimizers.SGD(0.001)\n",
        "\n",
        "num_epochs = 81\n",
        "num_episodes = 100\n",
        "save_path = \"./results/models/cifar100_train_reptile4.h5\"\n",
        "\n",
        "@tf.function\n",
        "def loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "@tf.function\n",
        "def train_step(support, query, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  \n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_acc(acc)\n",
        "  \n",
        "\n",
        "@tf.function\n",
        "def val_step(support, query, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss, acc = model(support, query)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(\n",
        "        zip(gradients, model.trainable_variables))\n",
        "  \n",
        "  val_loss(loss)\n",
        "  val_acc(acc)\n",
        "\n",
        "\n",
        "least_loss = {'least_loss': 100.00}\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss.reset_states()\n",
        "  val_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "  val_acc.reset_states()\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "    frac_done = episode / num_episodes\n",
        "    cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
        "    train_support, train_query = get_next_batch(train_images_split, train_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "    model = Prototypical(train_support, train_query, img_width, img_height, channels)\n",
        "    model.call(train_support, train_query)\n",
        "    old_weights = model.get_weights()\n",
        "    train_step(train_support, train_query, optimizer_adam)\n",
        "    new_weights = model.get_weights()\n",
        "\n",
        "    for part_weight in range(len(new_weights)):\n",
        "        new_weights[part_weight] = old_weights[part_weight] + (\n",
        "            (new_weights[part_weight] - old_weights[part_weight]) * cur_meta_step_size\n",
        "        )\n",
        "\n",
        "    model.set_weights(new_weights)\n",
        "    if epoch % eval_interval == 0:\n",
        "      eval_support, eval_query = get_next_batch(val_images_split, val_labels_split, num_way, num_shot, num_query, num_classes)\n",
        "      old_vars = model.get_weights()\n",
        "      val_step(eval_support, eval_query, optimizer_sgd)\n",
        "      model.set_weights(old_vars)\n",
        "      \n",
        "  cur_loss = val_loss.result().numpy()\n",
        "\n",
        "  if (epoch % eval_interval == 0):\n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, ' \\\n",
        "                  'Val Loss: {}, Val Accuracy: {}'\n",
        "    print(template.format(epoch + 1, train_loss.result(), train_acc.result() * 100, val_loss.result(),\n",
        "                            val_acc.result() * 100))\n",
        "    if cur_loss < least_loss['least_loss']:\n",
        "      print(\"Saving new best model with loss: \", cur_loss)\n",
        "      least_loss['least_loss'] = cur_loss\n",
        "      model.save(save_path)\n"
      ],
      "metadata": {
        "id": "wNWZObG6oU3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023f1f64-dfef-4d7e-d6d7-185b1a2f5228"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.613168716430664, Accuracy: 16.333335876464844, Val Loss: 2.6075093746185303, Val Accuracy: 17.20000457763672\n",
            "Saving new best model with loss:  2.6075094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 2.3286397457122803, Accuracy: 25.4888916015625, Val Loss: 2.3293654918670654, Val Accuracy: 24.24444007873535\n",
            "Saving new best model with loss:  2.3293655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 2.251028060913086, Accuracy: 27.400005340576172, Val Loss: 2.238393783569336, Val Accuracy: 27.511110305786133\n",
            "Saving new best model with loss:  2.2383938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 2.149437665939331, Accuracy: 30.111112594604492, Val Loss: 2.1758482456207275, Val Accuracy: 29.977781295776367\n",
            "Saving new best model with loss:  2.1758482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 2.0556371212005615, Accuracy: 32.55555725097656, Val Loss: 2.140754461288452, Val Accuracy: 32.11111068725586\n",
            "Saving new best model with loss:  2.1407545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Loss: 2.070406436920166, Accuracy: 32.84444046020508, Val Loss: 2.0445330142974854, Val Accuracy: 33.57778549194336\n",
            "Saving new best model with loss:  2.044533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Loss: 2.019033908843994, Accuracy: 33.599998474121094, Val Loss: 1.9891166687011719, Val Accuracy: 35.55555725097656\n",
            "Saving new best model with loss:  1.9891167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Loss: 1.9151192903518677, Accuracy: 37.95554733276367, Val Loss: 1.9219697713851929, Val Accuracy: 37.64445114135742\n",
            "Saving new best model with loss:  1.9219698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33, Loss: 1.8579940795898438, Accuracy: 38.866661071777344, Val Loss: 1.9158169031143188, Val Accuracy: 37.644439697265625\n",
            "Saving new best model with loss:  1.9158169\n",
            "Epoch 37, Loss: 1.8731883764266968, Accuracy: 38.4888916015625, Val Loss: 1.9209580421447754, Val Accuracy: 37.488887786865234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41, Loss: 1.8014700412750244, Accuracy: 41.93334197998047, Val Loss: 1.8151010274887085, Val Accuracy: 40.19999694824219\n",
            "Saving new best model with loss:  1.815101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Loss: 1.7707490921020508, Accuracy: 42.60000228881836, Val Loss: 1.791456699371338, Val Accuracy: 41.15555953979492\n",
            "Saving new best model with loss:  1.7914567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49, Loss: 1.715470790863037, Accuracy: 43.5111083984375, Val Loss: 1.7426986694335938, Val Accuracy: 43.88888931274414\n",
            "Saving new best model with loss:  1.7426987\n",
            "Epoch 53, Loss: 1.7043251991271973, Accuracy: 43.400001525878906, Val Loss: 1.7580196857452393, Val Accuracy: 41.99999237060547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57, Loss: 1.6116238832473755, Accuracy: 45.82221984863281, Val Loss: 1.7095319032669067, Val Accuracy: 43.42222213745117\n",
            "Saving new best model with loss:  1.7095319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61, Loss: 1.6152980327606201, Accuracy: 46.577781677246094, Val Loss: 1.6999226808547974, Val Accuracy: 44.133338928222656\n",
            "Saving new best model with loss:  1.6999227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65, Loss: 1.5428657531738281, Accuracy: 49.20000076293945, Val Loss: 1.6646288633346558, Val Accuracy: 45.20000076293945\n",
            "Saving new best model with loss:  1.6646289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69, Loss: 1.5404636859893799, Accuracy: 49.26667785644531, Val Loss: 1.652227759361267, Val Accuracy: 46.15556716918945\n",
            "Saving new best model with loss:  1.6522278\n",
            "Epoch 73, Loss: 1.527858018875122, Accuracy: 50.066673278808594, Val Loss: 1.674365520477295, Val Accuracy: 45.222232818603516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77, Loss: 1.4854035377502441, Accuracy: 50.80000305175781, Val Loss: 1.5978378057479858, Val Accuracy: 47.4666633605957\n",
            "Saving new best model with loss:  1.5978378\n",
            "Epoch 81, Loss: 1.4753289222717285, Accuracy: 51.53334045410156, Val Loss: 1.6137139797210693, Val Accuracy: 47.04442596435547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "model_path = \"./results/models/cifar100_train_reptile0.h5\"\n",
        "model.load(model_path)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[0] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[0]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[0] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "num_episodes = 1200\n",
        "\n",
        "# Metrics to gather\n",
        "test_loss = tf.metrics.Mean(name='test_loss')\n",
        "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
        "\n",
        "def calc_loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "  test_support, test_query = get_next_batch(test_images, test_labels, num_way, num_shot, num_query, num_classes)\n",
        "  if (i_episode+1)%50 == 0: \n",
        "    print(\"Episode: \", i_episode + 1)\n",
        "  loss, acc = calc_loss(test_support, test_query)\n",
        "  test_loss(loss)\n",
        "  test_acc(acc)\n",
        "\n",
        "print(\"Loss: \", test_loss.result().numpy())\n",
        "print(\"Accuracy: \", test_acc.result().numpy() * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY_lihJUzG38",
        "outputId": "f2a3473b-c66d-4870-a5a5-9d61cf73790d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Episode:  50\n",
            "Episode:  100\n",
            "Episode:  150\n",
            "Episode:  200\n",
            "Episode:  250\n",
            "Episode:  300\n",
            "Episode:  350\n",
            "Episode:  400\n",
            "Episode:  450\n",
            "Episode:  500\n",
            "Episode:  550\n",
            "Episode:  600\n",
            "Episode:  650\n",
            "Episode:  700\n",
            "Episode:  750\n",
            "Episode:  800\n",
            "Episode:  850\n",
            "Episode:  900\n",
            "Episode:  950\n",
            "Episode:  1000\n",
            "Episode:  1050\n",
            "Episode:  1100\n",
            "Episode:  1150\n",
            "Episode:  1200\n",
            "Loss:  1.6093277\n",
            "Accuracy:  35.81667244434357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "model_path = \"./results/models/cifar100_train_reptile1.h5\"\n",
        "model.load(model_path)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[1] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[1]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[1] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "num_episodes = 1200\n",
        "\n",
        "# Metrics to gather\n",
        "test_loss = tf.metrics.Mean(name='test_loss')\n",
        "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
        "\n",
        "def calc_loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "  test_support, test_query = get_next_batch(test_images, test_labels, num_way, num_shot, num_query, num_classes)\n",
        "  if (i_episode+1)%50 == 0: \n",
        "    print(\"Episode: \", i_episode + 1)\n",
        "  loss, acc = calc_loss(test_support, test_query)\n",
        "  test_loss(loss)\n",
        "  test_acc(acc)\n",
        "\n",
        "print(\"Loss: \", test_loss.result().numpy())\n",
        "print(\"Accuracy: \", test_acc.result().numpy() * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eeWK0EJ0CK_",
        "outputId": "59bc6d0a-17ad-4819-a613-48b33996e75e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Episode:  50\n",
            "Episode:  100\n",
            "Episode:  150\n",
            "Episode:  200\n",
            "Episode:  250\n",
            "Episode:  300\n",
            "Episode:  350\n",
            "Episode:  400\n",
            "Episode:  450\n",
            "Episode:  500\n",
            "Episode:  550\n",
            "Episode:  600\n",
            "Episode:  650\n",
            "Episode:  700\n",
            "Episode:  750\n",
            "Episode:  800\n",
            "Episode:  850\n",
            "Episode:  900\n",
            "Episode:  950\n",
            "Episode:  1000\n",
            "Episode:  1050\n",
            "Episode:  1100\n",
            "Episode:  1150\n",
            "Episode:  1200\n",
            "Loss:  1.6093526\n",
            "Accuracy:  29.933330416679382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "model_path = \"./results/models/cifar100_train_reptile2.h5\"\n",
        "model.load(model_path)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[2] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[2]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[2] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "num_episodes = 1200\n",
        "\n",
        "# Metrics to gather\n",
        "test_loss = tf.metrics.Mean(name='test_loss')\n",
        "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
        "\n",
        "def calc_loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "  test_support, test_query = get_next_batch(test_images, test_labels, num_way, num_shot, num_query, num_classes)\n",
        "  if (i_episode+1)%50 == 0: \n",
        "    print(\"Episode: \", i_episode + 1)\n",
        "  loss, acc = calc_loss(test_support, test_query)\n",
        "  test_loss(loss)\n",
        "  test_acc(acc)\n",
        "\n",
        "print(\"Loss: \", test_loss.result().numpy())\n",
        "print(\"Accuracy: \", test_acc.result().numpy() * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieGD779P0Csj",
        "outputId": "43b0d114-7b1d-4292-a2f3-4fda79820c26"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Episode:  50\n",
            "Episode:  100\n",
            "Episode:  150\n",
            "Episode:  200\n",
            "Episode:  250\n",
            "Episode:  300\n",
            "Episode:  350\n",
            "Episode:  400\n",
            "Episode:  450\n",
            "Episode:  500\n",
            "Episode:  550\n",
            "Episode:  600\n",
            "Episode:  650\n",
            "Episode:  700\n",
            "Episode:  750\n",
            "Episode:  800\n",
            "Episode:  850\n",
            "Episode:  900\n",
            "Episode:  950\n",
            "Episode:  1000\n",
            "Episode:  1050\n",
            "Episode:  1100\n",
            "Episode:  1150\n",
            "Episode:  1200\n",
            "Loss:  2.4847894\n",
            "Accuracy:  21.37497216463089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "model_path = \"./results/models/cifar100_train_reptile3.h5\"\n",
        "model.load(model_path)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[3] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[3]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[3] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "num_episodes = 1200\n",
        "\n",
        "# Metrics to gather\n",
        "test_loss = tf.metrics.Mean(name='test_loss')\n",
        "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
        "\n",
        "def calc_loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "  test_support, test_query = get_next_batch(test_images, test_labels, num_way, num_shot, num_query, num_classes)\n",
        "  if (i_episode+1)%50 == 0: \n",
        "    print(\"Episode: \", i_episode + 1)\n",
        "  loss, acc = calc_loss(test_support, test_query)\n",
        "  test_loss(loss)\n",
        "  test_acc(acc)\n",
        "\n",
        "print(\"Loss: \", test_loss.result().numpy())\n",
        "print(\"Accuracy: \", test_acc.result().numpy() * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bii5CZ1Q0DH5",
        "outputId": "dbd541ba-b259-4a13-c74a-c213f63dd53a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Episode:  50\n",
            "Episode:  100\n",
            "Episode:  150\n",
            "Episode:  200\n",
            "Episode:  250\n",
            "Episode:  300\n",
            "Episode:  350\n",
            "Episode:  400\n",
            "Episode:  450\n",
            "Episode:  500\n",
            "Episode:  550\n",
            "Episode:  600\n",
            "Episode:  650\n",
            "Episode:  700\n",
            "Episode:  750\n",
            "Episode:  800\n",
            "Episode:  850\n",
            "Episode:  900\n",
            "Episode:  950\n",
            "Episode:  1000\n",
            "Episode:  1050\n",
            "Episode:  1100\n",
            "Episode:  1150\n",
            "Episode:  1200\n",
            "Loss:  2.484716\n",
            "Accuracy:  14.090274274349213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Prototypical(support, query, img_width, img_height, channels)\n",
        "model_path = \"./results/models/cifar100_train_reptile4.h5\"\n",
        "model.load(model_path)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "#number of classes\n",
        "num_way = num_ways[4] \n",
        "\n",
        "#number of examples per class for support set\n",
        "num_shot = num_shots[4]  \n",
        "\n",
        "#number of query points\n",
        "num_query = num_shots[4] \n",
        "\n",
        "#number of examples\n",
        "num_examples = 100\n",
        "\n",
        "num_episodes = 1200\n",
        "\n",
        "# Metrics to gather\n",
        "test_loss = tf.metrics.Mean(name='test_loss')\n",
        "test_acc = tf.metrics.Mean(name='test_accuracy')\n",
        "\n",
        "def calc_loss(support, query):\n",
        "  loss, acc = model(support, query)\n",
        "  return loss, acc\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "  test_support, test_query = get_next_batch(test_images, test_labels, num_way, num_shot, num_query, num_classes)\n",
        "  if (i_episode+1)%50 == 0: \n",
        "    print(\"Episode: \", i_episode + 1)\n",
        "  loss, acc = calc_loss(test_support, test_query)\n",
        "  test_loss(loss)\n",
        "  test_acc(acc)\n",
        "\n",
        "print(\"Loss: \", test_loss.result().numpy())\n",
        "print(\"Accuracy: \", test_acc.result().numpy() * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHnBxSNP0DiN",
        "outputId": "d47a4e81-5762-46a9-e19c-45c9c634822e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Episode:  50\n",
            "Episode:  100\n",
            "Episode:  150\n",
            "Episode:  200\n",
            "Episode:  250\n",
            "Episode:  300\n",
            "Episode:  350\n",
            "Episode:  400\n",
            "Episode:  450\n",
            "Episode:  500\n",
            "Episode:  550\n",
            "Episode:  600\n",
            "Episode:  650\n",
            "Episode:  700\n",
            "Episode:  750\n",
            "Episode:  800\n",
            "Episode:  850\n",
            "Episode:  900\n",
            "Episode:  950\n",
            "Episode:  1000\n",
            "Episode:  1050\n",
            "Episode:  1100\n",
            "Episode:  1150\n",
            "Episode:  1200\n",
            "Loss:  2.7079453\n",
            "Accuracy:  17.59444624185562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import argmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# one hot encode\n",
        "train_labels_encoded = to_categorical(train_labels_split)\n",
        "val_labels_encoded = to_categorical(val_labels_split)\n",
        "test_labels_encoded = to_categorical(test_labels)\n",
        "print(train_labels_encoded.shape)\n",
        "print(test_labels_encoded.shape)\n",
        "print(train_images_split.shape)\n",
        "print(val_images_split.shape)\n",
        "print(test_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41CiZVmWBnB8",
        "outputId": "d4aac9b0-b066-4094-e097-5ec4feec4619"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 100)\n",
            "(10000, 100)\n",
            "(40000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, GlobalMaxPooling2D\n",
        "\n",
        "base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_width, img_height, channels))\n",
        "x = base_model.output\n",
        "x = GlobalMaxPooling2D()(x)\n",
        "x = Dropout(0.7)(x)\n",
        "predictions = Dense(100, activation= 'softmax')(x)\n",
        "model = Model(inputs = base_model.input, outputs = predictions)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer= optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_images_split, train_labels_encoded, epochs = 100, batch_size=64, validation_data=(val_images_split, val_labels_encoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkMkW5SWBn7v",
        "outputId": "7c37b13a-4057-4d0d-99fc-7f4ff993e925"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "625/625 [==============================] - 37s 49ms/step - loss: 5.6776 - accuracy: 0.0335 - val_loss: 28.8015 - val_accuracy: 0.0356\n",
            "Epoch 2/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 5.4656 - accuracy: 0.0429 - val_loss: 4.2122 - val_accuracy: 0.0527\n",
            "Epoch 3/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 5.3766 - accuracy: 0.0395 - val_loss: 32.6453 - val_accuracy: 0.0275\n",
            "Epoch 4/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 5.0128 - accuracy: 0.0500 - val_loss: 4.1106 - val_accuracy: 0.0593\n",
            "Epoch 5/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 4.8818 - accuracy: 0.0622 - val_loss: 4.2750 - val_accuracy: 0.0751\n",
            "Epoch 6/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 4.8766 - accuracy: 0.0617 - val_loss: 686.0621 - val_accuracy: 0.0135\n",
            "Epoch 7/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 4.6608 - accuracy: 0.0706 - val_loss: 8.4417 - val_accuracy: 0.0794\n",
            "Epoch 8/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 4.5914 - accuracy: 0.0767 - val_loss: 4.0697 - val_accuracy: 0.0706\n",
            "Epoch 9/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 4.5515 - accuracy: 0.0760 - val_loss: 4.8549 - val_accuracy: 0.0295\n",
            "Epoch 10/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 4.5792 - accuracy: 0.0692 - val_loss: 4.3721 - val_accuracy: 0.0541\n",
            "Epoch 11/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 4.5025 - accuracy: 0.0727 - val_loss: 348.0547 - val_accuracy: 0.0175\n",
            "Epoch 12/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 4.2071 - accuracy: 0.0910 - val_loss: 6.6443 - val_accuracy: 0.0903\n",
            "Epoch 13/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 4.1649 - accuracy: 0.1019 - val_loss: 5.7366 - val_accuracy: 0.1076\n",
            "Epoch 14/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 4.1468 - accuracy: 0.0959 - val_loss: 7.9957 - val_accuracy: 0.1102\n",
            "Epoch 15/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.9443 - accuracy: 0.1145 - val_loss: 6.1208 - val_accuracy: 0.0439\n",
            "Epoch 16/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.8473 - accuracy: 0.1268 - val_loss: 4.0520 - val_accuracy: 0.1316\n",
            "Epoch 17/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.8934 - accuracy: 0.1199 - val_loss: 3.8998 - val_accuracy: 0.1374\n",
            "Epoch 18/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.6949 - accuracy: 0.1400 - val_loss: 4.8980 - val_accuracy: 0.1251\n",
            "Epoch 19/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.6068 - accuracy: 0.1498 - val_loss: 5.4518 - val_accuracy: 0.0575\n",
            "Epoch 20/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.5599 - accuracy: 0.1520 - val_loss: 5.4645 - val_accuracy: 0.1632\n",
            "Epoch 21/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.5630 - accuracy: 0.1509 - val_loss: 3.8502 - val_accuracy: 0.1484\n",
            "Epoch 22/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.9935 - accuracy: 0.0905 - val_loss: 4.7826 - val_accuracy: 0.0537\n",
            "Epoch 23/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.8766 - accuracy: 0.1040 - val_loss: 4.2346 - val_accuracy: 0.1333\n",
            "Epoch 24/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.6811 - accuracy: 0.1337 - val_loss: 3.8431 - val_accuracy: 0.1492\n",
            "Epoch 25/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.5923 - accuracy: 0.1480 - val_loss: 22.4295 - val_accuracy: 0.0458\n",
            "Epoch 26/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.5562 - accuracy: 0.1550 - val_loss: 3.6225 - val_accuracy: 0.1466\n",
            "Epoch 27/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.6107 - accuracy: 0.1456 - val_loss: 4.1124 - val_accuracy: 0.1581\n",
            "Epoch 28/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.5375 - accuracy: 0.1560 - val_loss: 4.5715 - val_accuracy: 0.0536\n",
            "Epoch 29/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.5086 - accuracy: 0.1634 - val_loss: 4.9961 - val_accuracy: 0.0370\n",
            "Epoch 30/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.4453 - accuracy: 0.1740 - val_loss: 3.8619 - val_accuracy: 0.1757\n",
            "Epoch 31/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.3620 - accuracy: 0.1831 - val_loss: 3.9236 - val_accuracy: 0.1641\n",
            "Epoch 32/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.2996 - accuracy: 0.1952 - val_loss: 4.0543 - val_accuracy: 0.2004\n",
            "Epoch 33/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.6802 - accuracy: 0.1398 - val_loss: 5.2867 - val_accuracy: 0.0520\n",
            "Epoch 34/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.7484 - accuracy: 0.1246 - val_loss: 3.8018 - val_accuracy: 0.1331\n",
            "Epoch 35/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.4917 - accuracy: 0.1654 - val_loss: 3.5693 - val_accuracy: 0.1680\n",
            "Epoch 36/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.4231 - accuracy: 0.1771 - val_loss: 3.6244 - val_accuracy: 0.1764\n",
            "Epoch 37/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.3231 - accuracy: 0.1919 - val_loss: 3.5104 - val_accuracy: 0.1894\n",
            "Epoch 38/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.2916 - accuracy: 0.1997 - val_loss: 3.3654 - val_accuracy: 0.2023\n",
            "Epoch 39/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.2329 - accuracy: 0.2087 - val_loss: 3.6175 - val_accuracy: 0.1651\n",
            "Epoch 40/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.1969 - accuracy: 0.2163 - val_loss: 4.0227 - val_accuracy: 0.2033\n",
            "Epoch 41/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.1726 - accuracy: 0.2195 - val_loss: 3.6902 - val_accuracy: 0.1666\n",
            "Epoch 42/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.2266 - accuracy: 0.2141 - val_loss: 3.3181 - val_accuracy: 0.2176\n",
            "Epoch 43/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.1575 - accuracy: 0.2278 - val_loss: 3.5011 - val_accuracy: 0.2241\n",
            "Epoch 44/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.1150 - accuracy: 0.2355 - val_loss: 4.3125 - val_accuracy: 0.2239\n",
            "Epoch 45/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.0433 - accuracy: 0.2448 - val_loss: 3.9156 - val_accuracy: 0.2335\n",
            "Epoch 46/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.0748 - accuracy: 0.2383 - val_loss: 7.2228 - val_accuracy: 0.2225\n",
            "Epoch 47/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.0303 - accuracy: 0.2490 - val_loss: 3.7239 - val_accuracy: 0.1405\n",
            "Epoch 48/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 3.0902 - accuracy: 0.2385 - val_loss: 5.2085 - val_accuracy: 0.2169\n",
            "Epoch 49/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 3.0295 - accuracy: 0.2484 - val_loss: 6.3922 - val_accuracy: 0.2297\n",
            "Epoch 50/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 2.9472 - accuracy: 0.2625 - val_loss: 6.2056 - val_accuracy: 0.2467\n",
            "Epoch 51/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.8654 - accuracy: 0.2774 - val_loss: 6.3228 - val_accuracy: 0.2509\n",
            "Epoch 52/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.8670 - accuracy: 0.2786 - val_loss: 9.1738 - val_accuracy: 0.1235\n",
            "Epoch 53/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 2.9837 - accuracy: 0.2594 - val_loss: 5.8692 - val_accuracy: 0.2396\n",
            "Epoch 54/100\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 2.8439 - accuracy: 0.2798 - val_loss: 4.3457 - val_accuracy: 0.2512\n",
            "Epoch 55/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.7954 - accuracy: 0.2909 - val_loss: 9.0141 - val_accuracy: 0.2533\n",
            "Epoch 56/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.8065 - accuracy: 0.2870 - val_loss: 6.8920 - val_accuracy: 0.2542\n",
            "Epoch 57/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 2.7133 - accuracy: 0.3082 - val_loss: 11.5108 - val_accuracy: 0.2267\n",
            "Epoch 58/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.6533 - accuracy: 0.3190 - val_loss: 15.5552 - val_accuracy: 0.2591\n",
            "Epoch 59/100\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 2.6956 - accuracy: 0.3094 - val_loss: 11.0682 - val_accuracy: 0.2478\n",
            "Epoch 60/100\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 2.6583 - accuracy: 0.3138 - val_loss: 22.9400 - val_accuracy: 0.2535\n",
            "Epoch 61/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.5682 - accuracy: 0.3329 - val_loss: 39.1419 - val_accuracy: 0.2541\n",
            "Epoch 62/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 2.5167 - accuracy: 0.3424 - val_loss: 18.4104 - val_accuracy: 0.2607\n",
            "Epoch 63/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 2.4586 - accuracy: 0.3580 - val_loss: 31.0855 - val_accuracy: 0.2690\n",
            "Epoch 64/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.6153 - accuracy: 0.3243 - val_loss: 20.5899 - val_accuracy: 0.2051\n",
            "Epoch 65/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.4984 - accuracy: 0.3472 - val_loss: 120.2416 - val_accuracy: 0.2349\n",
            "Epoch 66/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 2.4057 - accuracy: 0.3654 - val_loss: 23.0105 - val_accuracy: 0.2638\n",
            "Epoch 67/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.3345 - accuracy: 0.3817 - val_loss: 28.8752 - val_accuracy: 0.2621\n",
            "Epoch 68/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.3706 - accuracy: 0.3728 - val_loss: 31.8546 - val_accuracy: 0.2642\n",
            "Epoch 69/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.2922 - accuracy: 0.3889 - val_loss: 18.1926 - val_accuracy: 0.2665\n",
            "Epoch 70/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 2.2162 - accuracy: 0.4043 - val_loss: 58.1904 - val_accuracy: 0.2587\n",
            "Epoch 71/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.1350 - accuracy: 0.4223 - val_loss: 23.4514 - val_accuracy: 0.2654\n",
            "Epoch 72/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.1903 - accuracy: 0.4118 - val_loss: 5.8990 - val_accuracy: 0.2289\n",
            "Epoch 73/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.2307 - accuracy: 0.4025 - val_loss: 6.8499 - val_accuracy: 0.2618\n",
            "Epoch 74/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 2.0977 - accuracy: 0.4307 - val_loss: 8.7648 - val_accuracy: 0.2645\n",
            "Epoch 75/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.0076 - accuracy: 0.4502 - val_loss: 15.4372 - val_accuracy: 0.2680\n",
            "Epoch 76/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 1.9346 - accuracy: 0.4646 - val_loss: 17.9655 - val_accuracy: 0.2606\n",
            "Epoch 77/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 1.8616 - accuracy: 0.4830 - val_loss: 20.0282 - val_accuracy: 0.2740\n",
            "Epoch 78/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.1085 - accuracy: 0.4384 - val_loss: 9.9177 - val_accuracy: 0.2275\n",
            "Epoch 79/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.5371 - accuracy: 0.3472 - val_loss: 12.2848 - val_accuracy: 0.2259\n",
            "Epoch 80/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.4245 - accuracy: 0.3676 - val_loss: 10.2931 - val_accuracy: 0.2430\n",
            "Epoch 81/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 2.2571 - accuracy: 0.3997 - val_loss: 10.7595 - val_accuracy: 0.2405\n",
            "Epoch 82/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.1676 - accuracy: 0.4173 - val_loss: 4.2161 - val_accuracy: 0.2336\n",
            "Epoch 83/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.1964 - accuracy: 0.4136 - val_loss: 13.1648 - val_accuracy: 0.2396\n",
            "Epoch 84/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 2.0192 - accuracy: 0.4525 - val_loss: 22.7034 - val_accuracy: 0.2467\n",
            "Epoch 85/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 2.0373 - accuracy: 0.4444 - val_loss: 6.1029 - val_accuracy: 0.2437\n",
            "Epoch 86/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 1.9259 - accuracy: 0.4705 - val_loss: 9.8410 - val_accuracy: 0.2466\n",
            "Epoch 87/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 1.8595 - accuracy: 0.4882 - val_loss: 11.5963 - val_accuracy: 0.2492\n",
            "Epoch 88/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 1.8828 - accuracy: 0.4861 - val_loss: 53.7205 - val_accuracy: 0.1543\n",
            "Epoch 89/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 1.8398 - accuracy: 0.4907 - val_loss: 6.8025 - val_accuracy: 0.2575\n",
            "Epoch 90/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 1.6699 - accuracy: 0.5304 - val_loss: 9.1974 - val_accuracy: 0.2579\n",
            "Epoch 91/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 1.7108 - accuracy: 0.5222 - val_loss: 84.6777 - val_accuracy: 0.2271\n",
            "Epoch 92/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 1.6372 - accuracy: 0.5383 - val_loss: 12.4104 - val_accuracy: 0.2478\n",
            "Epoch 93/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 1.5342 - accuracy: 0.5651 - val_loss: 10.3130 - val_accuracy: 0.2569\n",
            "Epoch 94/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 1.5220 - accuracy: 0.5666 - val_loss: 20.2884 - val_accuracy: 0.2499\n",
            "Epoch 95/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 1.7487 - accuracy: 0.5210 - val_loss: 126.2520 - val_accuracy: 0.2498\n",
            "Epoch 96/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 1.4990 - accuracy: 0.5781 - val_loss: 69.7664 - val_accuracy: 0.2524\n",
            "Epoch 97/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 1.3983 - accuracy: 0.6008 - val_loss: 60.8227 - val_accuracy: 0.2587\n",
            "Epoch 98/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 1.3763 - accuracy: 0.6033 - val_loss: 53.1659 - val_accuracy: 0.2516\n",
            "Epoch 99/100\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 1.3209 - accuracy: 0.6220 - val_loss: 60.9324 - val_accuracy: 0.2528\n",
            "Epoch 100/100\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 1.2724 - accuracy: 0.6316 - val_loss: 57.1306 - val_accuracy: 0.2554\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbfe782f510>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.evaluate(test_images, test_labels_encoded)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVP9e9YOBoVQ",
        "outputId": "53f4ac7e-da50-4378-8eb7-b1bf4c1de950"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 15ms/step - loss: 43.2228 - accuracy: 0.2587\n",
            "Loss = 43.22275161743164\n",
            "Test Accuracy = 0.25870001316070557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gj24Z8DNBouh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f4R_8juIBpI1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}